{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os, time\n",
    "import torch\n",
    "import utils\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.utils import shuffle\n",
    "from tensorboardX import SummaryWriter\n",
    "import traceback\n",
    "import importlib\n",
    "import global_params\n",
    "import monitor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeding Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_seed(args):\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = None\n",
    "approach = None\n",
    "network = None\n",
    "use_cuda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cuda_settings():\n",
    "    global use_cuda\n",
    "    if torch.cuda.is_available():\n",
    "        use_cuda = True\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    else:\n",
    "        use_cuda = False\n",
    "        print('[CUDA unavailable]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(args):\n",
    "    global dataloader\n",
    "    if args.experiment == 'cifar':\n",
    "        from dataloaders import cifar as dataloader\n",
    "    elif args.experiment == 'mixture':\n",
    "        from dataloaders import mixture as dataloader\n",
    "    elif args.experiment == 'mnist2':\n",
    "        from dataloaders import mnist2 as dataloader\n",
    "    elif args.experiment == 'pmnist':\n",
    "        from dataloaders import pmnist as dataloader\n",
    "    else:\n",
    "        dataloader = None\n",
    "        print('Dataset not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network_and_approach(args, approaches_dir='approaches', networks_dir='networks'):\n",
    "    global network, approach\n",
    "    network = importlib.import_module('.'+args.network, package=networks_dir)\n",
    "    approach = importlib.import_module('.'+args.approach, package=approaches_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # load settings\n",
    "    define_seed(args)\n",
    "    load_cuda_settings()\n",
    "    load_experiment(args)\n",
    "    load_network_and_approach(args)\n",
    "    \n",
    "    tstart=time.time()\n",
    "\n",
    "    # Load\n",
    "    print('Load data...')\n",
    "    data, taskcla, inputsize = dataloader.get(seed=args.seed)\n",
    "    print('Input size =', inputsize, '\\nTask info =', taskcla)\n",
    "\n",
    "    # Inits\n",
    "    print('Inits...')\n",
    "    net = network.Net(inputsize, taskcla)\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    params = utils.calculate_parameters(net)\n",
    "    print('Num parameters = %s' % (params))\n",
    "    if args.print_stats:\n",
    "        utils.print_model_report(net, params)\n",
    "\n",
    "    appr = approach.Appr(net, nepochs=args.nepochs, lr=args.lr, args=args, use_cuda=use_cuda)\n",
    "    if args.print_stats:\n",
    "        utils.print_optimizer_config(appr.optimizer)\n",
    "    print('-' * 100)\n",
    "\n",
    "    try:\n",
    "        # Loop tasks\n",
    "        acc = np.zeros((len(taskcla), len(taskcla)), dtype=np.float32)\n",
    "        lss = np.zeros((len(taskcla), len(taskcla)), dtype=np.float32)\n",
    "        for t, ncla in taskcla:\n",
    "            print('*' * 100)\n",
    "            print('Task {:2d} ({:s})'.format(t, data[t]['name']))\n",
    "            print('*' * 100)\n",
    "\n",
    "            if args.approach == 'joint':\n",
    "                # Get data. We do not put it to GPU\n",
    "                if t == 0:\n",
    "                    xtrain = data[t]['train']['x']\n",
    "                    ytrain = data[t]['train']['y']\n",
    "                    xvalid = data[t]['valid']['x']\n",
    "                    yvalid = data[t]['valid']['y']\n",
    "                    task_t = t * torch.ones(xtrain.size(0)).int()\n",
    "                    task_v = t * torch.ones(xvalid.size(0)).int()\n",
    "                    task = [task_t, task_v]\n",
    "                else:\n",
    "                    xtrain = torch.cat((xtrain, data[t]['train']['x']))\n",
    "                    ytrain = torch.cat((ytrain, data[t]['train']['y']))\n",
    "                    xvalid = torch.cat((xvalid, data[t]['valid']['x']))\n",
    "                    yvalid = torch.cat((yvalid, data[t]['valid']['y']))\n",
    "                    task_t = torch.cat((task_t, t * torch.ones(data[t]['train']['y'].size(0)).int()))\n",
    "                    task_v = torch.cat((task_v, t * torch.ones(data[t]['valid']['y'].size(0)).int()))\n",
    "                    task = [task_t, task_v]\n",
    "            else:\n",
    "                # Get data\n",
    "                xtrain = data[t]['train']['x']\n",
    "                ytrain = data[t]['train']['y']\n",
    "                xvalid = data[t]['valid']['x']\n",
    "                yvalid = data[t]['valid']['y']\n",
    "                if use_cuda:\n",
    "                    xtrain = xtrain.cuda()\n",
    "                    ytrain = ytrain.cuda()\n",
    "                    xvalid = xvalid.cuda()\n",
    "                    yvalid = yvalid.cuda()\n",
    "\n",
    "                task = t\n",
    "\n",
    "            # Train\n",
    "            appr.train(task, xtrain, ytrain, xvalid, yvalid)\n",
    "            print('-' * 100)\n",
    "\n",
    "            # Test\n",
    "            for u in range(t + 1):\n",
    "                xtest = data[u]['test']['x']\n",
    "                ytest = data[u]['test']['y']\n",
    "                if use_cuda:\n",
    "                    xtest = xtest.cuda()\n",
    "                    ytest = ytest.cuda()\n",
    "                test_loss, test_acc = appr.eval(u, xtest, ytest)\n",
    "                print('>>> Test on task {:2d} - {:15s}: loss={:.3f}, acc={:5.1f}% <<<'.format(u, data[u]['name'], test_loss,\n",
    "                                                                                              100 * test_acc))\n",
    "                acc[t, u] = test_acc\n",
    "                lss[t, u] = test_loss\n",
    "\n",
    "            # Save\n",
    "            print('Save at ' + args.output)\n",
    "            np.savetxt(args.output, acc, '%.4f')\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        return net\n",
    "\n",
    "    # Done\n",
    "    print('*' * 100)\n",
    "    print('Accuracies =')\n",
    "    for i in range(acc.shape[0]):\n",
    "        print('\\t', end='')\n",
    "        for j in range(acc.shape[1]):\n",
    "            print('{:5.1f}% '.format(100 * acc[i, j]), end='')\n",
    "        print()\n",
    "    print('*' * 100)\n",
    "    print('Done!')\n",
    "\n",
    "    print('[Elapsed time = {:.1f} h]'.format((time.time() - tstart) / (60 * 60)))\n",
    "\n",
    "    if hasattr(appr, 'logs'):\n",
    "        if appr.logs is not None:\n",
    "            # save task names\n",
    "            from copy import deepcopy\n",
    "            appr.logs['task_name'] = {}\n",
    "            appr.logs['test_acc'] = {}\n",
    "            appr.logs['test_loss'] = {}\n",
    "            for t, ncla in taskcla:\n",
    "                appr.logs['task_name'][t] = deepcopy(data[t]['name'])\n",
    "                appr.logs['test_acc'][t] = deepcopy(acc[t, :])\n",
    "                appr.logs['test_loss'][t] = deepcopy(lss[t, :])\n",
    "            # pickle\n",
    "            import gzip\n",
    "            import pickle\n",
    "            with gzip.open(os.path.join(appr.logpath), 'wb') as output:\n",
    "                pickle.dump(appr.logs, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = global_params.args\n",
    "args.seed = 0\n",
    "args.experiment = 'cifar'\n",
    "args.approach = 'si_xda'\n",
    "args.network = 'alexnet_'\n",
    "args.output = 'res/'+args.network+args.experiment+'_'+args.approach+'_'+str(args.seed)+'.txt'\n",
    "args.comment = 'alexnet_'+args.approach\n",
    "\n",
    "# change due to other naming convention in approaches\n",
    "args.network = args.network + args.approach\n",
    "args.print_stats = False\n",
    "args.nepochs = 200\n",
    "args.lr = 0.05\n",
    "args.enable_logging = True\n",
    "args.log_steps = 1000\n",
    "args.logger = monitor.Logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Task order = [2, 8, 4, 9, 1, 6, 7, 3, 0, 5]\n",
      "Input size = [3, 32, 32] \n",
      "Task info = [(0, 2), (1, 20), (2, 2), (3, 20), (4, 2), (5, 20), (6, 20), (7, 2), (8, 2), (9, 20)]\n",
      "Inits...\n",
      "Num parameters = 7.6M\n",
      "Setting parameters to c-0.1, xi-0.001, decay-0.5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "****************************************************************************************************\n",
      "Task  0 (cifar10-2)\n",
      "****************************************************************************************************\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 19.9ms/  5.1ms | Train: loss=1.844, acc= 65.5% | Valid: loss=1.828, acc= 67.1% | *\n",
      "| Epoch   2, time= 14.5ms/  4.5ms | Train: loss=1.581, acc= 70.5% | Valid: loss=1.563, acc= 72.2% | *\n",
      "| Epoch   3, time= 14.7ms/  4.4ms | Train: loss=1.353, acc= 78.1% | Valid: loss=1.324, acc= 79.8% | *\n",
      "| Epoch   4, time= 14.4ms/  4.4ms | Train: loss=1.245, acc= 81.5% | Valid: loss=1.222, acc= 81.6% | *\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 14.5ms/  4.4ms | Train: loss=1.169, acc= 83.2% | Valid: loss=1.154, acc= 83.5% | *\n",
      "| Epoch   6, time= 14.6ms/  4.5ms | Train: loss=1.335, acc= 76.6% | Valid: loss=1.307, acc= 77.8% |\n",
      "| Epoch   7, time= 14.4ms/  4.4ms | Train: loss=1.082, acc= 84.0% | Valid: loss=1.070, acc= 84.8% | *\n",
      "| Epoch   8, time= 14.4ms/  4.4ms | Train: loss=1.052, acc= 84.6% | Valid: loss=1.045, acc= 85.0% | *\n",
      "tensor(0.0707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 14.4ms/  4.5ms | Train: loss=1.030, acc= 85.6% | Valid: loss=1.028, acc= 85.2% | *\n",
      "| Epoch  10, time= 14.4ms/  4.5ms | Train: loss=1.068, acc= 83.0% | Valid: loss=1.071, acc= 84.6% |\n",
      "| Epoch  11, time= 14.3ms/  4.4ms | Train: loss=1.190, acc= 76.0% | Valid: loss=1.201, acc= 78.5% |\n",
      "| Epoch  12, time= 14.4ms/  4.4ms | Train: loss=0.956, acc= 88.3% | Valid: loss=0.975, acc= 86.1% | *\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 14.4ms/  4.5ms | Train: loss=1.008, acc= 85.0% | Valid: loss=1.044, acc= 83.5% |\n",
      "| Epoch  14, time= 14.6ms/  4.4ms | Train: loss=0.937, acc= 89.4% | Valid: loss=0.978, acc= 86.3% |\n",
      "| Epoch  15, time= 14.5ms/  4.4ms | Train: loss=0.958, acc= 88.1% | Valid: loss=0.994, acc= 86.4% |\n",
      "| Epoch  16, time= 14.4ms/  4.4ms | Train: loss=0.952, acc= 88.3% | Valid: loss=0.989, acc= 86.2% |\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 14.5ms/  4.5ms | Train: loss=0.909, acc= 90.2% | Valid: loss=0.957, acc= 86.4% | *\n",
      "| Epoch  18, time= 14.5ms/  4.4ms | Train: loss=0.893, acc= 91.5% | Valid: loss=0.947, acc= 87.8% | *\n",
      "| Epoch  19, time= 14.4ms/  4.4ms | Train: loss=0.877, acc= 91.7% | Valid: loss=0.932, acc= 87.5% | *\n",
      "| Epoch  20, time= 14.4ms/  4.4ms | Train: loss=0.895, acc= 90.9% | Valid: loss=0.962, acc= 86.7% |\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 14.5ms/  4.4ms | Train: loss=0.865, acc= 92.4% | Valid: loss=0.928, acc= 89.3% | *\n",
      "| Epoch  22, time= 15.1ms/  4.5ms | Train: loss=0.901, acc= 90.7% | Valid: loss=0.971, acc= 86.2% |\n",
      "| Epoch  23, time= 14.8ms/  4.4ms | Train: loss=0.852, acc= 92.7% | Valid: loss=0.925, acc= 88.0% | *\n",
      "| Epoch  24, time= 15.0ms/  4.5ms | Train: loss=0.854, acc= 93.0% | Valid: loss=0.931, acc= 88.4% |\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 14.6ms/  4.5ms | Train: loss=0.866, acc= 92.2% | Valid: loss=0.942, acc= 87.5% |\n",
      "| Epoch  26, time= 14.4ms/  4.5ms | Train: loss=0.846, acc= 92.4% | Valid: loss=0.957, acc= 87.7% |\n",
      "| Epoch  27, time= 14.5ms/  4.5ms | Train: loss=0.798, acc= 94.8% | Valid: loss=0.907, acc= 88.1% | *\n",
      "| Epoch  28, time= 14.4ms/  4.5ms | Train: loss=0.827, acc= 93.3% | Valid: loss=0.935, acc= 88.2% |\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 14.5ms/  4.5ms | Train: loss=0.793, acc= 94.7% | Valid: loss=0.900, acc= 89.0% | *\n",
      "| Epoch  30, time= 14.4ms/  4.5ms | Train: loss=0.819, acc= 92.9% | Valid: loss=0.950, acc= 87.7% |\n",
      "| Epoch  31, time= 14.4ms/  4.5ms | Train: loss=0.805, acc= 93.1% | Valid: loss=0.938, acc= 88.1% |\n",
      "| Epoch  32, time= 14.5ms/  4.5ms | Train: loss=0.836, acc= 91.3% | Valid: loss=0.976, acc= 85.6% |\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 14.5ms/  4.5ms | Train: loss=0.807, acc= 93.5% | Valid: loss=0.937, acc= 87.1% |\n",
      "| Epoch  34, time= 14.4ms/  4.5ms | Train: loss=0.894, acc= 89.0% | Valid: loss=1.051, acc= 85.3% | lr=1.7e-02\n",
      "| Epoch  35, time= 14.4ms/  4.5ms | Train: loss=0.720, acc= 97.1% | Valid: loss=0.889, acc= 89.7% | *\n",
      "| Epoch  36, time= 14.9ms/  4.5ms | Train: loss=0.699, acc= 97.3% | Valid: loss=0.875, acc= 90.0% | *\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 14.5ms/  5.0ms | Train: loss=0.694, acc= 97.6% | Valid: loss=0.872, acc= 91.4% | *\n",
      "| Epoch  38, time= 14.7ms/  4.4ms | Train: loss=0.677, acc= 97.9% | Valid: loss=0.874, acc= 90.4% |\n",
      "| Epoch  39, time= 14.5ms/  4.4ms | Train: loss=0.681, acc= 97.4% | Valid: loss=0.917, acc= 89.7% |\n",
      "| Epoch  40, time= 14.3ms/  4.5ms | Train: loss=0.657, acc= 98.2% | Valid: loss=0.892, acc= 90.2% |\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 14.7ms/  4.5ms | Train: loss=0.660, acc= 98.1% | Valid: loss=0.894, acc= 89.9% |\n",
      "| Epoch  42, time= 14.4ms/  4.5ms | Train: loss=0.662, acc= 98.0% | Valid: loss=0.908, acc= 90.2% | lr=5.6e-03\n",
      "| Epoch  43, time= 14.5ms/  4.4ms | Train: loss=0.649, acc= 98.3% | Valid: loss=0.903, acc= 90.2% |\n",
      "| Epoch  44, time= 14.5ms/  4.5ms | Train: loss=0.634, acc= 98.8% | Valid: loss=0.893, acc= 90.6% |\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 14.5ms/  4.5ms | Train: loss=0.633, acc= 98.7% | Valid: loss=0.914, acc= 90.4% |\n",
      "| Epoch  46, time= 14.4ms/  4.5ms | Train: loss=0.627, acc= 99.0% | Valid: loss=0.898, acc= 89.9% |\n",
      "| Epoch  47, time= 14.6ms/  4.5ms | Train: loss=0.633, acc= 98.6% | Valid: loss=0.918, acc= 90.6% | lr=1.9e-03\n",
      "| Epoch  48, time= 14.4ms/  4.9ms | Train: loss=0.623, acc= 99.1% | Valid: loss=0.891, acc= 90.9% |\n",
      "tensor(0.0594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 14.8ms/  4.7ms | Train: loss=0.621, acc= 99.2% | Valid: loss=0.898, acc= 90.5% |\n",
      "| Epoch  50, time= 14.7ms/  4.5ms | Train: loss=0.619, acc= 99.2% | Valid: loss=0.900, acc= 90.6% |\n",
      "| Epoch  51, time= 14.4ms/  4.4ms | Train: loss=0.618, acc= 99.2% | Valid: loss=0.910, acc= 90.7% |\n",
      "| Epoch  52, time= 14.4ms/  4.5ms | Train: loss=0.615, acc= 99.3% | Valid: loss=0.898, acc= 90.7% | lr=6.2e-04\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 14.4ms/  4.5ms | Train: loss=0.614, acc= 99.3% | Valid: loss=0.900, acc= 90.6% |\n",
      "| Epoch  54, time= 14.4ms/  4.4ms | Train: loss=0.614, acc= 99.3% | Valid: loss=0.900, acc= 90.8% |\n",
      "| Epoch  55, time= 14.4ms/  4.4ms | Train: loss=0.613, acc= 99.2% | Valid: loss=0.904, acc= 90.7% |\n",
      "| Epoch  56, time= 14.4ms/  4.4ms | Train: loss=0.613, acc= 99.3% | Valid: loss=0.902, acc= 90.3% |\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 14.5ms/  4.5ms | Train: loss=0.612, acc= 99.4% | Valid: loss=0.905, acc= 90.4% | lr=2.1e-04\n",
      "| Epoch  58, time= 14.6ms/  4.8ms | Train: loss=0.613, acc= 99.3% | Valid: loss=0.907, acc= 90.5% |\n",
      "| Epoch  59, time= 14.6ms/  4.6ms | Train: loss=0.612, acc= 99.3% | Valid: loss=0.906, acc= 90.6% |\n",
      "| Epoch  60, time= 14.5ms/  4.4ms | Train: loss=0.612, acc= 99.3% | Valid: loss=0.905, acc= 90.4% |\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 14.5ms/  4.5ms | Train: loss=0.612, acc= 99.4% | Valid: loss=0.903, acc= 90.6% |\n",
      "| Epoch  62, time= 14.4ms/  4.4ms | Train: loss=0.611, acc= 99.4% | Valid: loss=0.903, acc= 90.7% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.854, acc= 90.0% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  1 (cifar100-3)\n",
      "****************************************************************************************************\n",
      "tensor(0.8332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 37.4ms/ 11.8ms | Train: loss=3.806, acc= 26.1% | Valid: loss=3.796, acc= 26.2% | *\n",
      "| Epoch   2, time= 36.9ms/ 11.8ms | Train: loss=3.130, acc= 40.3% | Valid: loss=3.137, acc= 40.9% | *\n",
      "| Epoch   3, time= 37.1ms/ 11.7ms | Train: loss=3.123, acc= 40.1% | Valid: loss=3.129, acc= 40.3% | *\n",
      "| Epoch   4, time= 37.0ms/ 11.7ms | Train: loss=3.000, acc= 44.0% | Valid: loss=2.980, acc= 44.3% | *\n",
      "tensor(1.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.5ms/ 12.8ms | Train: loss=3.252, acc= 37.0% | Valid: loss=3.287, acc= 37.3% |\n",
      "| Epoch   6, time= 36.7ms/ 11.7ms | Train: loss=3.150, acc= 40.2% | Valid: loss=3.210, acc= 40.8% |\n",
      "| Epoch   7, time= 35.7ms/ 12.0ms | Train: loss=2.977, acc= 45.0% | Valid: loss=3.017, acc= 44.7% |\n",
      "| Epoch   8, time= 38.0ms/ 12.1ms | Train: loss=2.954, acc= 45.5% | Valid: loss=3.034, acc= 42.5% |\n",
      "tensor(1.8637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 38.0ms/ 11.7ms | Train: loss=2.732, acc= 53.2% | Valid: loss=2.772, acc= 51.7% | *\n",
      "| Epoch  10, time= 37.6ms/ 12.0ms | Train: loss=3.551, acc= 37.3% | Valid: loss=3.610, acc= 37.5% |\n",
      "| Epoch  11, time= 37.3ms/ 12.5ms | Train: loss=2.920, acc= 46.4% | Valid: loss=3.024, acc= 43.4% |\n",
      "| Epoch  12, time= 37.3ms/ 11.8ms | Train: loss=2.685, acc= 53.5% | Valid: loss=2.748, acc= 50.3% | *\n",
      "tensor(2.1176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 37.1ms/ 11.7ms | Train: loss=2.782, acc= 51.6% | Valid: loss=2.860, acc= 50.8% |\n",
      "| Epoch  14, time= 36.9ms/ 11.7ms | Train: loss=2.807, acc= 50.0% | Valid: loss=2.904, acc= 47.9% |\n",
      "| Epoch  15, time= 36.3ms/ 11.8ms | Train: loss=2.864, acc= 47.1% | Valid: loss=2.983, acc= 43.8% |\n",
      "| Epoch  16, time= 36.4ms/ 11.6ms | Train: loss=2.762, acc= 52.8% | Valid: loss=2.889, acc= 49.5% |\n",
      "tensor(2.3095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.4ms/ 11.6ms | Train: loss=2.757, acc= 52.1% | Valid: loss=2.872, acc= 49.2% | lr=1.7e-02\n",
      "| Epoch  18, time= 36.7ms/ 11.7ms | Train: loss=2.388, acc= 62.7% | Valid: loss=2.579, acc= 57.5% | *\n",
      "| Epoch  19, time= 36.9ms/ 11.7ms | Train: loss=2.327, acc= 64.7% | Valid: loss=2.528, acc= 59.6% | *\n",
      "| Epoch  20, time= 36.2ms/ 11.7ms | Train: loss=2.303, acc= 65.5% | Valid: loss=2.525, acc= 58.5% | *\n",
      "tensor(1.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 36.6ms/ 11.6ms | Train: loss=2.301, acc= 64.9% | Valid: loss=2.531, acc= 59.4% |\n",
      "| Epoch  22, time= 37.1ms/ 12.3ms | Train: loss=2.303, acc= 65.5% | Valid: loss=2.544, acc= 59.2% |\n",
      "| Epoch  23, time= 36.4ms/ 11.6ms | Train: loss=2.293, acc= 65.0% | Valid: loss=2.545, acc= 59.0% |\n",
      "| Epoch  24, time= 36.7ms/ 11.6ms | Train: loss=2.297, acc= 64.5% | Valid: loss=2.540, acc= 58.9% |\n",
      "tensor(1.9710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 37.4ms/ 11.8ms | Train: loss=2.281, acc= 65.5% | Valid: loss=2.559, acc= 57.6% | lr=5.6e-03\n",
      "| Epoch  26, time= 36.7ms/ 11.7ms | Train: loss=2.178, acc= 69.0% | Valid: loss=2.478, acc= 61.8% | *\n",
      "| Epoch  27, time= 36.6ms/ 11.7ms | Train: loss=2.163, acc= 68.8% | Valid: loss=2.481, acc= 61.2% |\n",
      "| Epoch  28, time= 36.7ms/ 11.7ms | Train: loss=2.120, acc= 70.2% | Valid: loss=2.456, acc= 61.4% | *\n",
      "tensor(1.8268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 37.0ms/ 11.8ms | Train: loss=2.107, acc= 70.5% | Valid: loss=2.456, acc= 60.7% | *\n",
      "| Epoch  30, time= 36.3ms/ 11.6ms | Train: loss=2.137, acc= 69.5% | Valid: loss=2.463, acc= 61.0% |\n",
      "| Epoch  31, time= 36.6ms/ 11.7ms | Train: loss=2.107, acc= 70.5% | Valid: loss=2.463, acc= 60.6% |\n",
      "| Epoch  32, time= 36.4ms/ 11.6ms | Train: loss=2.075, acc= 71.1% | Valid: loss=2.435, acc= 61.6% | *\n",
      "tensor(1.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 36.3ms/ 11.8ms | Train: loss=2.070, acc= 71.7% | Valid: loss=2.432, acc= 62.2% | *\n",
      "| Epoch  34, time= 37.5ms/ 12.1ms | Train: loss=2.067, acc= 71.5% | Valid: loss=2.432, acc= 61.8% |\n",
      "| Epoch  35, time= 36.6ms/ 11.8ms | Train: loss=2.058, acc= 71.9% | Valid: loss=2.431, acc= 62.8% | *\n",
      "| Epoch  36, time= 36.7ms/ 11.6ms | Train: loss=2.093, acc= 70.5% | Valid: loss=2.482, acc= 60.6% |\n",
      "tensor(1.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 36.7ms/ 11.7ms | Train: loss=2.067, acc= 71.7% | Valid: loss=2.458, acc= 60.6% |\n",
      "| Epoch  38, time= 36.5ms/ 11.7ms | Train: loss=2.033, acc= 72.9% | Valid: loss=2.427, acc= 62.2% | *\n",
      "| Epoch  39, time= 37.2ms/ 11.6ms | Train: loss=2.036, acc= 72.7% | Valid: loss=2.425, acc= 61.9% | *\n",
      "| Epoch  40, time= 36.4ms/ 11.7ms | Train: loss=2.027, acc= 72.2% | Valid: loss=2.418, acc= 61.8% | *\n",
      "tensor(1.7893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 36.5ms/ 11.7ms | Train: loss=2.012, acc= 73.1% | Valid: loss=2.421, acc= 61.3% |\n",
      "| Epoch  42, time= 37.0ms/ 11.8ms | Train: loss=2.010, acc= 73.0% | Valid: loss=2.426, acc= 62.9% |\n",
      "| Epoch  43, time= 36.7ms/ 11.6ms | Train: loss=2.015, acc= 72.9% | Valid: loss=2.438, acc= 60.8% |\n",
      "| Epoch  44, time= 36.6ms/ 11.6ms | Train: loss=2.003, acc= 73.2% | Valid: loss=2.426, acc= 62.3% |\n",
      "tensor(1.7993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.2ms/ 11.9ms | Train: loss=1.974, acc= 74.3% | Valid: loss=2.383, acc= 62.6% | *\n",
      "| Epoch  46, time= 37.4ms/ 11.7ms | Train: loss=1.992, acc= 73.5% | Valid: loss=2.430, acc= 62.7% |\n",
      "| Epoch  47, time= 36.8ms/ 11.7ms | Train: loss=2.028, acc= 72.2% | Valid: loss=2.481, acc= 61.2% |\n",
      "| Epoch  48, time= 36.5ms/ 11.7ms | Train: loss=2.011, acc= 72.6% | Valid: loss=2.453, acc= 61.5% |\n",
      "tensor(1.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 36.3ms/ 11.7ms | Train: loss=1.966, acc= 74.1% | Valid: loss=2.426, acc= 62.4% |\n",
      "| Epoch  50, time= 36.6ms/ 11.6ms | Train: loss=1.979, acc= 74.0% | Valid: loss=2.427, acc= 62.0% | lr=1.9e-03\n",
      "| Epoch  51, time= 36.8ms/ 11.7ms | Train: loss=1.929, acc= 75.5% | Valid: loss=2.389, acc= 62.6% |\n",
      "| Epoch  52, time= 36.7ms/ 11.9ms | Train: loss=1.936, acc= 75.4% | Valid: loss=2.400, acc= 63.1% |\n",
      "tensor(1.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 37.6ms/ 11.7ms | Train: loss=1.910, acc= 75.8% | Valid: loss=2.381, acc= 63.3% | *\n",
      "| Epoch  54, time= 37.2ms/ 13.1ms | Train: loss=1.918, acc= 75.4% | Valid: loss=2.396, acc= 63.1% |\n",
      "| Epoch  55, time= 37.3ms/ 11.7ms | Train: loss=1.916, acc= 75.8% | Valid: loss=2.389, acc= 63.8% |\n",
      "| Epoch  56, time= 36.6ms/ 11.7ms | Train: loss=1.912, acc= 75.7% | Valid: loss=2.398, acc= 63.2% |\n",
      "tensor(1.7592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.5ms/ 11.6ms | Train: loss=1.900, acc= 76.1% | Valid: loss=2.384, acc= 65.0% |\n",
      "| Epoch  58, time= 36.5ms/ 11.7ms | Train: loss=1.899, acc= 75.8% | Valid: loss=2.388, acc= 63.8% | lr=6.2e-04\n",
      "| Epoch  59, time= 36.8ms/ 11.8ms | Train: loss=1.890, acc= 76.6% | Valid: loss=2.385, acc= 63.9% |\n",
      "| Epoch  60, time= 36.8ms/ 11.7ms | Train: loss=1.886, acc= 76.6% | Valid: loss=2.384, acc= 63.5% |\n",
      "tensor(1.7465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.4ms/ 12.0ms | Train: loss=1.896, acc= 76.4% | Valid: loss=2.389, acc= 63.8% |\n",
      "| Epoch  62, time= 36.8ms/ 11.7ms | Train: loss=1.886, acc= 76.5% | Valid: loss=2.381, acc= 63.1% |\n",
      "| Epoch  63, time= 36.3ms/ 11.8ms | Train: loss=1.879, acc= 76.8% | Valid: loss=2.379, acc= 63.0% | *\n",
      "| Epoch  64, time= 36.4ms/ 11.6ms | Train: loss=1.885, acc= 76.7% | Valid: loss=2.383, acc= 63.6% |\n",
      "tensor(1.7409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 36.4ms/ 12.2ms | Train: loss=1.880, acc= 76.9% | Valid: loss=2.380, acc= 63.2% |\n",
      "| Epoch  66, time= 36.2ms/ 11.7ms | Train: loss=1.886, acc= 76.5% | Valid: loss=2.383, acc= 63.7% |\n",
      "| Epoch  67, time= 37.0ms/ 11.7ms | Train: loss=1.882, acc= 76.5% | Valid: loss=2.376, acc= 63.3% | *\n",
      "| Epoch  68, time= 36.6ms/ 11.7ms | Train: loss=1.888, acc= 76.6% | Valid: loss=2.381, acc= 63.8% |\n",
      "tensor(1.7376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  69, time= 36.5ms/ 11.7ms | Train: loss=1.884, acc= 76.5% | Valid: loss=2.386, acc= 63.1% |\n",
      "| Epoch  70, time= 36.6ms/ 11.8ms | Train: loss=1.873, acc= 76.9% | Valid: loss=2.376, acc= 63.3% |\n",
      "| Epoch  71, time= 36.4ms/ 11.6ms | Train: loss=1.880, acc= 76.6% | Valid: loss=2.383, acc= 63.9% |\n",
      "| Epoch  72, time= 36.4ms/ 12.4ms | Train: loss=1.867, acc= 77.2% | Valid: loss=2.378, acc= 63.3% | lr=2.1e-04\n",
      "tensor(1.7350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  73, time= 37.4ms/ 12.1ms | Train: loss=1.869, acc= 76.8% | Valid: loss=2.374, acc= 63.3% | *\n",
      "| Epoch  74, time= 36.8ms/ 11.8ms | Train: loss=1.874, acc= 77.0% | Valid: loss=2.379, acc= 63.7% |\n",
      "| Epoch  75, time= 36.6ms/ 11.8ms | Train: loss=1.875, acc= 76.7% | Valid: loss=2.381, acc= 63.6% |\n",
      "| Epoch  76, time= 36.8ms/ 12.2ms | Train: loss=1.872, acc= 76.8% | Valid: loss=2.377, acc= 63.6% |\n",
      "tensor(1.7326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  77, time= 36.8ms/ 12.1ms | Train: loss=1.867, acc= 77.1% | Valid: loss=2.376, acc= 63.3% |\n",
      "| Epoch  78, time= 36.6ms/ 11.7ms | Train: loss=1.874, acc= 76.8% | Valid: loss=2.382, acc= 63.2% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.888, acc= 89.1% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=31.156, acc= 60.0% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  2 (cifar10-4)\n",
      "****************************************************************************************************\n",
      "tensor(0.9331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 36.6ms/ 12.7ms | Train: loss=1.856, acc= 84.1% | Valid: loss=1.886, acc= 82.5% | *\n",
      "| Epoch   2, time= 37.2ms/ 11.7ms | Train: loss=1.694, acc= 82.7% | Valid: loss=1.730, acc= 80.9% | *\n",
      "| Epoch   3, time= 38.6ms/ 12.7ms | Train: loss=1.979, acc= 64.4% | Valid: loss=2.027, acc= 63.5% |\n",
      "| Epoch   4, time= 36.3ms/ 12.2ms | Train: loss=1.679, acc= 82.8% | Valid: loss=1.712, acc= 80.7% | *\n",
      "tensor(0.9615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 39.1ms/ 13.0ms | Train: loss=2.321, acc= 60.0% | Valid: loss=2.362, acc= 59.5% |\n",
      "| Epoch   6, time= 37.7ms/ 12.5ms | Train: loss=1.660, acc= 84.9% | Valid: loss=1.703, acc= 82.6% | *\n",
      "| Epoch   7, time= 38.8ms/ 11.8ms | Train: loss=2.431, acc= 54.1% | Valid: loss=2.465, acc= 53.9% |\n",
      "| Epoch   8, time= 37.8ms/ 12.0ms | Train: loss=1.669, acc= 84.4% | Valid: loss=1.704, acc= 82.4% |\n",
      "tensor(0.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 37.6ms/ 12.9ms | Train: loss=1.648, acc= 86.4% | Valid: loss=1.684, acc= 84.8% | *\n",
      "| Epoch  10, time= 37.6ms/ 11.8ms | Train: loss=1.690, acc= 83.5% | Valid: loss=1.726, acc= 81.6% |\n",
      "| Epoch  11, time= 38.7ms/ 12.3ms | Train: loss=2.003, acc= 67.7% | Valid: loss=2.032, acc= 66.5% |\n",
      "| Epoch  12, time= 36.9ms/ 11.7ms | Train: loss=1.663, acc= 84.1% | Valid: loss=1.711, acc= 81.8% |\n",
      "tensor(1.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 38.1ms/ 12.0ms | Train: loss=1.738, acc= 79.8% | Valid: loss=1.768, acc= 79.8% |\n",
      "| Epoch  14, time= 36.4ms/ 11.9ms | Train: loss=1.712, acc= 81.6% | Valid: loss=1.764, acc= 79.2% | lr=1.7e-02\n",
      "| Epoch  15, time= 37.4ms/ 11.8ms | Train: loss=1.654, acc= 85.9% | Valid: loss=1.687, acc= 84.9% |\n",
      "| Epoch  16, time= 36.4ms/ 11.7ms | Train: loss=1.618, acc= 88.1% | Valid: loss=1.656, acc= 87.2% | *\n",
      "tensor(0.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.4ms/ 11.7ms | Train: loss=1.597, acc= 88.7% | Valid: loss=1.637, acc= 87.6% | *\n",
      "| Epoch  18, time= 36.7ms/ 11.7ms | Train: loss=1.572, acc= 89.7% | Valid: loss=1.612, acc= 89.1% | *\n",
      "| Epoch  19, time= 36.4ms/ 12.8ms | Train: loss=1.969, acc= 73.2% | Valid: loss=1.994, acc= 72.6% |\n",
      "| Epoch  20, time= 37.2ms/ 12.2ms | Train: loss=1.858, acc= 76.0% | Valid: loss=1.891, acc= 75.2% |\n",
      "tensor(0.7430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 37.6ms/ 11.7ms | Train: loss=1.559, acc= 89.6% | Valid: loss=1.601, acc= 87.9% | *\n",
      "| Epoch  22, time= 36.5ms/ 11.8ms | Train: loss=1.793, acc= 77.4% | Valid: loss=1.816, acc= 76.2% |\n",
      "| Epoch  23, time= 36.7ms/ 11.7ms | Train: loss=1.568, acc= 88.7% | Valid: loss=1.605, acc= 88.8% |\n",
      "| Epoch  24, time= 37.4ms/ 11.6ms | Train: loss=1.568, acc= 89.6% | Valid: loss=1.618, acc= 88.5% |\n",
      "tensor(0.7377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 37.3ms/ 11.7ms | Train: loss=1.555, acc= 89.4% | Valid: loss=1.590, acc= 89.0% | *\n",
      "| Epoch  26, time= 36.6ms/ 11.7ms | Train: loss=1.584, acc= 87.7% | Valid: loss=1.622, acc= 86.3% |\n",
      "| Epoch  27, time= 36.4ms/ 11.6ms | Train: loss=1.573, acc= 88.3% | Valid: loss=1.611, acc= 87.5% |\n",
      "| Epoch  28, time= 37.2ms/ 11.7ms | Train: loss=1.542, acc= 89.6% | Valid: loss=1.575, acc= 88.6% | *\n",
      "tensor(0.7475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.6ms/ 11.7ms | Train: loss=1.517, acc= 90.9% | Valid: loss=1.557, acc= 89.7% | *\n",
      "| Epoch  30, time= 35.8ms/ 11.8ms | Train: loss=1.519, acc= 90.5% | Valid: loss=1.568, acc= 88.7% |\n",
      "| Epoch  31, time= 36.7ms/ 11.7ms | Train: loss=1.613, acc= 84.7% | Valid: loss=1.645, acc= 84.8% |\n",
      "| Epoch  32, time= 36.1ms/ 12.5ms | Train: loss=1.506, acc= 90.4% | Valid: loss=1.546, acc= 89.5% | *\n",
      "tensor(0.7788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 36.1ms/ 11.7ms | Train: loss=1.530, acc= 89.8% | Valid: loss=1.570, acc= 88.7% |\n",
      "| Epoch  34, time= 36.5ms/ 11.7ms | Train: loss=1.508, acc= 90.4% | Valid: loss=1.562, acc= 88.6% |\n",
      "| Epoch  35, time= 37.0ms/ 11.7ms | Train: loss=1.517, acc= 89.7% | Valid: loss=1.563, acc= 87.7% |\n",
      "| Epoch  36, time= 37.1ms/ 12.0ms | Train: loss=1.532, acc= 89.3% | Valid: loss=1.575, acc= 88.2% |\n",
      "tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 37.6ms/ 11.7ms | Train: loss=1.530, acc= 89.0% | Valid: loss=1.566, acc= 88.4% | lr=5.6e-03\n",
      "| Epoch  38, time= 36.7ms/ 11.7ms | Train: loss=1.509, acc= 89.9% | Valid: loss=1.553, acc= 89.2% |\n",
      "| Epoch  39, time= 36.2ms/ 11.7ms | Train: loss=1.498, acc= 90.8% | Valid: loss=1.542, acc= 89.2% | *\n",
      "| Epoch  40, time= 36.6ms/ 11.7ms | Train: loss=1.484, acc= 91.9% | Valid: loss=1.529, acc= 90.0% | *\n",
      "tensor(0.6587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 37.2ms/ 11.8ms | Train: loss=1.489, acc= 90.9% | Valid: loss=1.533, acc= 89.4% |\n",
      "| Epoch  42, time= 36.6ms/ 12.0ms | Train: loss=1.465, acc= 92.1% | Valid: loss=1.513, acc= 91.0% | *\n",
      "| Epoch  43, time= 36.4ms/ 11.6ms | Train: loss=1.489, acc= 91.0% | Valid: loss=1.531, acc= 90.2% |\n",
      "| Epoch  44, time= 36.5ms/ 11.6ms | Train: loss=1.487, acc= 91.3% | Valid: loss=1.529, acc= 89.8% |\n",
      "tensor(0.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.1ms/ 12.5ms | Train: loss=1.475, acc= 91.6% | Valid: loss=1.529, acc= 90.6% |\n",
      "| Epoch  46, time= 36.6ms/ 11.8ms | Train: loss=1.563, acc= 87.5% | Valid: loss=1.609, acc= 87.2% |\n",
      "| Epoch  47, time= 36.8ms/ 11.7ms | Train: loss=1.465, acc= 92.1% | Valid: loss=1.517, acc= 89.5% | lr=1.9e-03\n",
      "| Epoch  48, time= 36.7ms/ 11.7ms | Train: loss=1.479, acc= 90.9% | Valid: loss=1.527, acc= 90.1% |\n",
      "tensor(0.6154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 36.6ms/ 11.7ms | Train: loss=1.473, acc= 91.2% | Valid: loss=1.522, acc= 89.8% |\n",
      "| Epoch  50, time= 37.0ms/ 11.7ms | Train: loss=1.465, acc= 91.7% | Valid: loss=1.513, acc= 90.4% | *\n",
      "| Epoch  51, time= 36.1ms/ 11.7ms | Train: loss=1.457, acc= 92.2% | Valid: loss=1.506, acc= 90.7% | *\n",
      "| Epoch  52, time= 36.3ms/ 11.8ms | Train: loss=1.481, acc= 91.1% | Valid: loss=1.530, acc= 89.9% |\n",
      "tensor(0.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.5ms/ 11.7ms | Train: loss=1.476, acc= 91.2% | Valid: loss=1.523, acc= 90.1% |\n",
      "| Epoch  54, time= 37.0ms/ 11.7ms | Train: loss=1.465, acc= 91.7% | Valid: loss=1.514, acc= 90.5% |\n",
      "| Epoch  55, time= 36.6ms/ 11.8ms | Train: loss=1.459, acc= 91.8% | Valid: loss=1.507, acc= 90.8% |\n",
      "| Epoch  56, time= 36.8ms/ 11.7ms | Train: loss=1.445, acc= 92.8% | Valid: loss=1.498, acc= 90.7% | *\n",
      "tensor(0.5786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.9ms/ 11.7ms | Train: loss=1.499, acc= 90.0% | Valid: loss=1.545, acc= 89.3% |\n",
      "| Epoch  58, time= 36.1ms/ 12.6ms | Train: loss=1.445, acc= 92.8% | Valid: loss=1.496, acc= 90.8% | *\n",
      "| Epoch  59, time= 36.6ms/ 11.7ms | Train: loss=1.456, acc= 92.2% | Valid: loss=1.507, acc= 90.7% |\n",
      "| Epoch  60, time= 36.7ms/ 11.6ms | Train: loss=1.460, acc= 92.2% | Valid: loss=1.510, acc= 91.2% |\n",
      "tensor(0.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.7ms/ 11.7ms | Train: loss=1.460, acc= 92.0% | Valid: loss=1.511, acc= 90.5% |\n",
      "| Epoch  62, time= 36.7ms/ 11.8ms | Train: loss=1.442, acc= 93.0% | Valid: loss=1.500, acc= 91.1% |\n",
      "| Epoch  63, time= 37.3ms/ 11.7ms | Train: loss=1.449, acc= 92.4% | Valid: loss=1.501, acc= 90.8% | lr=6.2e-04\n",
      "| Epoch  64, time= 37.0ms/ 11.8ms | Train: loss=1.454, acc= 92.4% | Valid: loss=1.506, acc= 90.8% |\n",
      "tensor(0.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 36.9ms/ 11.8ms | Train: loss=1.455, acc= 92.4% | Valid: loss=1.508, acc= 91.0% |\n",
      "| Epoch  66, time= 36.7ms/ 11.7ms | Train: loss=1.459, acc= 91.9% | Valid: loss=1.511, acc= 90.8% |\n",
      "| Epoch  67, time= 38.0ms/ 12.1ms | Train: loss=1.455, acc= 92.1% | Valid: loss=1.507, acc= 90.8% |\n",
      "| Epoch  68, time= 36.3ms/ 11.8ms | Train: loss=1.448, acc= 92.4% | Valid: loss=1.502, acc= 91.1% | lr=2.1e-04\n",
      "tensor(0.5589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  69, time= 36.9ms/ 11.8ms | Train: loss=1.448, acc= 92.5% | Valid: loss=1.501, acc= 91.2% |\n",
      "| Epoch  70, time= 36.5ms/ 11.7ms | Train: loss=1.448, acc= 92.4% | Valid: loss=1.502, acc= 91.0% |\n",
      "| Epoch  71, time= 36.6ms/ 11.8ms | Train: loss=1.448, acc= 92.5% | Valid: loss=1.504, acc= 91.1% |\n",
      "| Epoch  72, time= 36.2ms/ 11.8ms | Train: loss=1.447, acc= 92.6% | Valid: loss=1.501, acc= 91.1% |\n",
      "tensor(0.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  73, time= 36.8ms/ 12.1ms | Train: loss=1.447, acc= 92.6% | Valid: loss=1.500, acc= 91.0% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.898, acc= 88.4% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=11.962, acc= 58.0% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=10.968, acc= 90.5% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  3 (cifar100-4)\n",
      "****************************************************************************************************\n",
      "tensor(1.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 36.8ms/ 11.6ms | Train: loss=3.851, acc= 34.0% | Valid: loss=3.882, acc= 35.0% | *\n",
      "| Epoch   2, time= 37.2ms/ 12.3ms | Train: loss=3.634, acc= 35.8% | Valid: loss=3.732, acc= 32.7% | *\n",
      "| Epoch   3, time= 37.3ms/ 11.7ms | Train: loss=3.557, acc= 34.9% | Valid: loss=3.647, acc= 33.5% | *\n",
      "| Epoch   4, time= 37.0ms/ 11.7ms | Train: loss=3.558, acc= 38.3% | Valid: loss=3.663, acc= 35.3% |\n",
      "tensor(3.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.4ms/ 11.8ms | Train: loss=3.459, acc= 40.5% | Valid: loss=3.570, acc= 37.1% | *\n",
      "| Epoch   6, time= 36.3ms/ 11.8ms | Train: loss=3.360, acc= 41.7% | Valid: loss=3.477, acc= 39.3% | *\n",
      "| Epoch   7, time= 37.1ms/ 11.7ms | Train: loss=3.378, acc= 43.5% | Valid: loss=3.513, acc= 39.5% |\n",
      "| Epoch   8, time= 36.7ms/ 11.7ms | Train: loss=3.366, acc= 44.1% | Valid: loss=3.521, acc= 40.8% |\n",
      "tensor(3.6468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.5866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 37.0ms/ 11.8ms | Train: loss=3.370, acc= 43.9% | Valid: loss=3.522, acc= 41.1% |\n",
      "| Epoch  10, time= 36.4ms/ 11.7ms | Train: loss=3.169, acc= 48.8% | Valid: loss=3.295, acc= 44.8% | *\n",
      "| Epoch  11, time= 37.2ms/ 11.6ms | Train: loss=3.517, acc= 38.9% | Valid: loss=3.628, acc= 35.9% |\n",
      "| Epoch  12, time= 36.5ms/ 11.7ms | Train: loss=3.666, acc= 33.0% | Valid: loss=3.801, acc= 29.8% |\n",
      "tensor(4.1087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 36.9ms/ 11.8ms | Train: loss=3.531, acc= 40.8% | Valid: loss=3.602, acc= 38.0% |\n",
      "| Epoch  14, time= 37.0ms/ 11.7ms | Train: loss=3.262, acc= 45.6% | Valid: loss=3.422, acc= 41.5% |\n",
      "| Epoch  15, time= 36.7ms/ 12.5ms | Train: loss=3.550, acc= 39.6% | Valid: loss=3.689, acc= 35.9% | lr=1.7e-02\n",
      "| Epoch  16, time= 36.7ms/ 11.7ms | Train: loss=2.780, acc= 57.6% | Valid: loss=2.960, acc= 52.0% | *\n",
      "tensor(3.1654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.8ms/ 11.7ms | Train: loss=2.895, acc= 54.4% | Valid: loss=3.104, acc= 47.7% |\n",
      "| Epoch  18, time= 36.7ms/ 11.7ms | Train: loss=2.639, acc= 61.2% | Valid: loss=2.852, acc= 54.7% | *\n",
      "| Epoch  19, time= 36.7ms/ 11.9ms | Train: loss=2.707, acc= 58.3% | Valid: loss=2.906, acc= 52.8% |\n",
      "| Epoch  20, time= 37.5ms/ 11.7ms | Train: loss=2.650, acc= 60.2% | Valid: loss=2.873, acc= 51.8% |\n",
      "tensor(2.8697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 36.5ms/ 11.7ms | Train: loss=2.718, acc= 58.7% | Valid: loss=2.946, acc= 52.4% |\n",
      "| Epoch  22, time= 36.7ms/ 11.8ms | Train: loss=2.710, acc= 58.6% | Valid: loss=2.931, acc= 52.6% |\n",
      "| Epoch  23, time= 36.3ms/ 11.7ms | Train: loss=2.649, acc= 59.7% | Valid: loss=2.870, acc= 53.5% | lr=5.6e-03\n",
      "| Epoch  24, time= 37.3ms/ 11.6ms | Train: loss=2.488, acc= 64.1% | Valid: loss=2.736, acc= 57.0% | *\n",
      "tensor(2.5472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 36.6ms/ 11.6ms | Train: loss=2.429, acc= 65.8% | Valid: loss=2.703, acc= 57.6% | *\n",
      "| Epoch  26, time= 37.0ms/ 11.8ms | Train: loss=2.393, acc= 66.5% | Valid: loss=2.653, acc= 58.0% | *\n",
      "| Epoch  27, time= 36.6ms/ 11.7ms | Train: loss=2.445, acc= 64.1% | Valid: loss=2.706, acc= 56.5% |\n",
      "| Epoch  28, time= 36.6ms/ 12.1ms | Train: loss=2.400, acc= 66.4% | Valid: loss=2.690, acc= 58.6% |\n",
      "tensor(2.3620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.8ms/ 11.6ms | Train: loss=2.387, acc= 67.0% | Valid: loss=2.662, acc= 58.8% |\n",
      "| Epoch  30, time= 36.5ms/ 11.8ms | Train: loss=2.384, acc= 66.7% | Valid: loss=2.681, acc= 56.9% |\n",
      "| Epoch  31, time= 36.3ms/ 11.7ms | Train: loss=2.387, acc= 66.0% | Valid: loss=2.668, acc= 57.8% | lr=1.9e-03\n",
      "| Epoch  32, time= 36.4ms/ 11.8ms | Train: loss=2.326, acc= 68.2% | Valid: loss=2.610, acc= 59.6% | *\n",
      "tensor(2.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 37.3ms/ 12.8ms | Train: loss=2.307, acc= 68.7% | Valid: loss=2.609, acc= 59.7% | *\n",
      "| Epoch  34, time= 37.3ms/ 12.0ms | Train: loss=2.310, acc= 68.5% | Valid: loss=2.612, acc= 59.5% |\n",
      "| Epoch  35, time= 37.7ms/ 12.2ms | Train: loss=2.306, acc= 68.8% | Valid: loss=2.608, acc= 59.7% | *\n",
      "| Epoch  36, time= 37.4ms/ 12.8ms | Train: loss=2.320, acc= 68.3% | Valid: loss=2.629, acc= 59.7% |\n",
      "tensor(2.1689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 38.3ms/ 11.7ms | Train: loss=2.290, acc= 68.9% | Valid: loss=2.603, acc= 59.9% | *\n",
      "| Epoch  38, time= 36.8ms/ 11.7ms | Train: loss=2.296, acc= 68.6% | Valid: loss=2.614, acc= 58.7% |\n",
      "| Epoch  39, time= 36.4ms/ 11.7ms | Train: loss=2.280, acc= 68.9% | Valid: loss=2.591, acc= 59.3% | *\n",
      "| Epoch  40, time= 36.4ms/ 11.7ms | Train: loss=2.267, acc= 69.7% | Valid: loss=2.586, acc= 59.5% | *\n",
      "tensor(2.1262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 37.5ms/ 11.7ms | Train: loss=2.268, acc= 69.6% | Valid: loss=2.593, acc= 60.3% |\n",
      "| Epoch  42, time= 36.9ms/ 11.7ms | Train: loss=2.274, acc= 69.5% | Valid: loss=2.592, acc= 60.6% |\n",
      "| Epoch  43, time= 37.6ms/ 11.8ms | Train: loss=2.266, acc= 69.6% | Valid: loss=2.588, acc= 61.0% |\n",
      "| Epoch  44, time= 36.8ms/ 11.8ms | Train: loss=2.265, acc= 70.0% | Valid: loss=2.592, acc= 59.8% |\n",
      "tensor(2.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.9ms/ 12.4ms | Train: loss=2.270, acc= 69.6% | Valid: loss=2.603, acc= 60.0% | lr=6.2e-04\n",
      "| Epoch  46, time= 36.8ms/ 11.7ms | Train: loss=2.259, acc= 70.0% | Valid: loss=2.587, acc= 60.1% |\n",
      "| Epoch  47, time= 36.8ms/ 11.7ms | Train: loss=2.253, acc= 70.2% | Valid: loss=2.584, acc= 60.3% | *\n",
      "| Epoch  48, time= 36.3ms/ 11.6ms | Train: loss=2.245, acc= 70.3% | Valid: loss=2.581, acc= 60.8% | *\n",
      "tensor(2.0749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 36.8ms/ 11.7ms | Train: loss=2.240, acc= 70.1% | Valid: loss=2.580, acc= 59.4% | *\n",
      "| Epoch  50, time= 37.7ms/ 11.7ms | Train: loss=2.248, acc= 70.4% | Valid: loss=2.581, acc= 60.3% |\n",
      "| Epoch  51, time= 36.5ms/ 11.6ms | Train: loss=2.243, acc= 70.3% | Valid: loss=2.585, acc= 60.0% |\n",
      "| Epoch  52, time= 36.5ms/ 11.6ms | Train: loss=2.237, acc= 70.5% | Valid: loss=2.574, acc= 59.9% | *\n",
      "tensor(2.0536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.7ms/ 11.7ms | Train: loss=2.247, acc= 70.4% | Valid: loss=2.579, acc= 60.2% |\n",
      "| Epoch  54, time= 37.2ms/ 11.7ms | Train: loss=2.240, acc= 70.4% | Valid: loss=2.579, acc= 60.1% |\n",
      "| Epoch  55, time= 36.6ms/ 11.7ms | Train: loss=2.238, acc= 70.6% | Valid: loss=2.576, acc= 59.9% |\n",
      "| Epoch  56, time= 36.7ms/ 11.7ms | Train: loss=2.241, acc= 70.6% | Valid: loss=2.583, acc= 60.9% |\n",
      "tensor(2.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.6ms/ 11.7ms | Train: loss=2.237, acc= 70.7% | Valid: loss=2.571, acc= 60.4% | *\n",
      "| Epoch  58, time= 37.1ms/ 11.9ms | Train: loss=2.238, acc= 70.3% | Valid: loss=2.576, acc= 59.9% |\n",
      "| Epoch  59, time= 36.4ms/ 11.8ms | Train: loss=2.231, acc= 70.9% | Valid: loss=2.569, acc= 61.3% | *\n",
      "| Epoch  60, time= 36.6ms/ 11.7ms | Train: loss=2.238, acc= 70.3% | Valid: loss=2.576, acc= 60.0% |\n",
      "tensor(2.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.9ms/ 11.7ms | Train: loss=2.229, acc= 70.6% | Valid: loss=2.571, acc= 60.4% |\n",
      "| Epoch  62, time= 36.8ms/ 11.6ms | Train: loss=2.225, acc= 70.9% | Valid: loss=2.575, acc= 59.7% |\n",
      "| Epoch  63, time= 37.2ms/ 11.7ms | Train: loss=2.228, acc= 70.9% | Valid: loss=2.577, acc= 60.2% |\n",
      "| Epoch  64, time= 36.4ms/ 11.6ms | Train: loss=2.227, acc= 70.7% | Valid: loss=2.567, acc= 60.3% | *\n",
      "tensor(2.0246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 36.8ms/ 11.7ms | Train: loss=2.221, acc= 70.9% | Valid: loss=2.568, acc= 60.3% |\n",
      "| Epoch  66, time= 36.8ms/ 11.7ms | Train: loss=2.224, acc= 70.8% | Valid: loss=2.577, acc= 59.8% |\n",
      "| Epoch  67, time= 37.2ms/ 11.8ms | Train: loss=2.220, acc= 70.9% | Valid: loss=2.574, acc= 60.2% |\n",
      "| Epoch  68, time= 36.5ms/ 11.7ms | Train: loss=2.213, acc= 71.3% | Valid: loss=2.565, acc= 60.1% | *\n",
      "tensor(2.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  69, time= 36.8ms/ 11.7ms | Train: loss=2.218, acc= 71.0% | Valid: loss=2.576, acc= 59.3% |\n",
      "| Epoch  70, time= 36.0ms/ 11.8ms | Train: loss=2.221, acc= 70.8% | Valid: loss=2.573, acc= 60.6% |\n",
      "| Epoch  71, time= 39.4ms/ 12.8ms | Train: loss=2.217, acc= 70.8% | Valid: loss=2.559, acc= 59.9% | *\n",
      "| Epoch  72, time= 37.8ms/ 12.3ms | Train: loss=2.209, acc= 71.0% | Valid: loss=2.559, acc= 60.7% | *\n",
      "tensor(2.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  73, time= 38.7ms/ 11.6ms | Train: loss=2.209, acc= 71.1% | Valid: loss=2.569, acc= 60.4% |\n",
      "| Epoch  74, time= 36.6ms/ 11.7ms | Train: loss=2.212, acc= 71.1% | Valid: loss=2.575, acc= 60.2% |\n",
      "| Epoch  75, time= 36.5ms/ 12.9ms | Train: loss=2.211, acc= 70.9% | Valid: loss=2.567, acc= 60.6% |\n",
      "| Epoch  76, time= 37.2ms/ 11.7ms | Train: loss=2.203, acc= 71.2% | Valid: loss=2.553, acc= 60.9% | *\n",
      "tensor(2.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  77, time= 36.5ms/ 11.8ms | Train: loss=2.206, acc= 71.3% | Valid: loss=2.555, acc= 60.7% |\n",
      "| Epoch  78, time= 36.1ms/ 11.7ms | Train: loss=2.211, acc= 71.2% | Valid: loss=2.551, acc= 60.7% | *\n",
      "| Epoch  79, time= 36.4ms/ 11.7ms | Train: loss=2.196, acc= 71.2% | Valid: loss=2.545, acc= 60.8% | *\n",
      "| Epoch  80, time= 37.3ms/ 11.8ms | Train: loss=2.199, acc= 71.5% | Valid: loss=2.543, acc= 61.1% | *\n",
      "tensor(1.9904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  81, time= 36.5ms/ 11.7ms | Train: loss=2.199, acc= 71.6% | Valid: loss=2.552, acc= 61.5% |\n",
      "| Epoch  82, time= 36.5ms/ 11.7ms | Train: loss=2.203, acc= 71.1% | Valid: loss=2.565, acc= 60.5% |\n",
      "| Epoch  83, time= 36.8ms/ 11.7ms | Train: loss=2.210, acc= 71.3% | Valid: loss=2.569, acc= 61.0% |\n",
      "| Epoch  84, time= 36.7ms/ 11.8ms | Train: loss=2.212, acc= 71.2% | Valid: loss=2.571, acc= 60.5% |\n",
      "tensor(1.9853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  85, time= 36.9ms/ 11.7ms | Train: loss=2.201, acc= 71.2% | Valid: loss=2.553, acc= 60.1% | lr=2.1e-04\n",
      "| Epoch  86, time= 36.1ms/ 11.7ms | Train: loss=2.190, acc= 71.6% | Valid: loss=2.547, acc= 61.8% |\n",
      "| Epoch  87, time= 36.5ms/ 11.8ms | Train: loss=2.194, acc= 71.5% | Valid: loss=2.553, acc= 60.8% |\n",
      "| Epoch  88, time= 36.5ms/ 12.4ms | Train: loss=2.198, acc= 71.5% | Valid: loss=2.555, acc= 60.8% |\n",
      "tensor(1.9800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  89, time= 36.4ms/ 11.7ms | Train: loss=2.200, acc= 71.4% | Valid: loss=2.558, acc= 60.6% |\n",
      "| Epoch  90, time= 36.2ms/ 11.8ms | Train: loss=2.194, acc= 71.7% | Valid: loss=2.554, acc= 61.3% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.918, acc= 89.0% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=27.971, acc= 59.9% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=27.089, acc= 87.8% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=27.935, acc= 60.3% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  4 (cifar10-1)\n",
      "****************************************************************************************************\n",
      "tensor(0.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 36.7ms/ 11.7ms | Train: loss=2.205, acc= 74.9% | Valid: loss=2.246, acc= 73.1% | *\n",
      "| Epoch   2, time= 36.6ms/ 12.3ms | Train: loss=2.031, acc= 70.5% | Valid: loss=2.067, acc= 68.2% | *\n",
      "| Epoch   3, time= 36.3ms/ 11.7ms | Train: loss=2.352, acc= 54.6% | Valid: loss=2.383, acc= 53.8% |\n",
      "| Epoch   4, time= 36.3ms/ 11.8ms | Train: loss=1.944, acc= 77.2% | Valid: loss=1.978, acc= 74.5% | *\n",
      "tensor(1.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.2ms/ 11.7ms | Train: loss=1.870, acc= 79.1% | Valid: loss=1.921, acc= 75.6% | *\n",
      "| Epoch   6, time= 36.4ms/ 11.7ms | Train: loss=1.866, acc= 80.0% | Valid: loss=1.912, acc= 76.5% | *\n",
      "| Epoch   7, time= 37.0ms/ 11.7ms | Train: loss=2.200, acc= 53.8% | Valid: loss=2.235, acc= 53.1% |\n",
      "| Epoch   8, time= 36.7ms/ 11.8ms | Train: loss=1.859, acc= 78.2% | Valid: loss=1.895, acc= 74.9% | *\n",
      "tensor(0.8727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 36.9ms/ 11.7ms | Train: loss=2.164, acc= 60.1% | Valid: loss=2.199, acc= 58.9% |\n",
      "| Epoch  10, time= 36.6ms/ 11.7ms | Train: loss=1.912, acc= 72.9% | Valid: loss=1.953, acc= 71.3% |\n",
      "| Epoch  11, time= 37.5ms/ 11.9ms | Train: loss=1.846, acc= 77.8% | Valid: loss=1.884, acc= 75.8% | *\n",
      "| Epoch  12, time= 36.4ms/ 11.6ms | Train: loss=1.873, acc= 72.8% | Valid: loss=1.906, acc= 69.9% |\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 37.2ms/ 11.7ms | Train: loss=1.950, acc= 67.4% | Valid: loss=1.991, acc= 67.1% |\n",
      "| Epoch  14, time= 36.8ms/ 11.8ms | Train: loss=1.980, acc= 65.3% | Valid: loss=2.016, acc= 63.0% |\n",
      "| Epoch  15, time= 36.8ms/ 12.4ms | Train: loss=1.903, acc= 69.1% | Valid: loss=1.944, acc= 68.1% |\n",
      "| Epoch  16, time= 36.8ms/ 11.7ms | Train: loss=1.917, acc= 69.0% | Valid: loss=1.962, acc= 67.0% | lr=1.7e-02\n",
      "tensor(0.9169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.5ms/ 11.8ms | Train: loss=1.801, acc= 76.6% | Valid: loss=1.846, acc= 73.9% | *\n",
      "| Epoch  18, time= 37.3ms/ 11.7ms | Train: loss=1.721, acc= 82.7% | Valid: loss=1.774, acc= 79.9% | *\n",
      "| Epoch  19, time= 36.8ms/ 11.8ms | Train: loss=1.780, acc= 77.5% | Valid: loss=1.836, acc= 74.3% |\n",
      "| Epoch  20, time= 36.8ms/ 11.6ms | Train: loss=1.715, acc= 81.6% | Valid: loss=1.766, acc= 79.0% | *\n",
      "tensor(0.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 37.1ms/ 11.7ms | Train: loss=1.690, acc= 83.0% | Valid: loss=1.738, acc= 80.0% | *\n",
      "| Epoch  22, time= 36.4ms/ 11.8ms | Train: loss=1.691, acc= 83.1% | Valid: loss=1.740, acc= 80.7% |\n",
      "| Epoch  23, time= 36.5ms/ 11.7ms | Train: loss=1.680, acc= 83.5% | Valid: loss=1.725, acc= 80.2% | *\n",
      "| Epoch  24, time= 37.5ms/ 11.8ms | Train: loss=1.681, acc= 82.9% | Valid: loss=1.732, acc= 80.3% |\n",
      "tensor(0.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 36.8ms/ 11.8ms | Train: loss=1.793, acc= 75.1% | Valid: loss=1.848, acc= 72.9% |\n",
      "| Epoch  26, time= 36.9ms/ 11.6ms | Train: loss=1.668, acc= 84.4% | Valid: loss=1.719, acc= 81.1% | *\n",
      "| Epoch  27, time= 36.7ms/ 11.7ms | Train: loss=2.256, acc= 56.6% | Valid: loss=2.321, acc= 55.5% |\n",
      "| Epoch  28, time= 36.5ms/ 12.5ms | Train: loss=1.673, acc= 83.4% | Valid: loss=1.738, acc= 79.6% |\n",
      "tensor(0.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 37.3ms/ 11.6ms | Train: loss=1.660, acc= 83.9% | Valid: loss=1.714, acc= 81.8% | *\n",
      "| Epoch  30, time= 36.8ms/ 11.6ms | Train: loss=1.722, acc= 78.5% | Valid: loss=1.770, acc= 76.0% |\n",
      "| Epoch  31, time= 36.7ms/ 11.7ms | Train: loss=1.658, acc= 82.7% | Valid: loss=1.713, acc= 79.5% | *\n",
      "| Epoch  32, time= 36.7ms/ 11.6ms | Train: loss=1.800, acc= 74.1% | Valid: loss=1.846, acc= 73.0% |\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 37.2ms/ 11.7ms | Train: loss=1.653, acc= 83.4% | Valid: loss=1.706, acc= 80.2% | *\n",
      "| Epoch  34, time= 37.0ms/ 11.8ms | Train: loss=1.651, acc= 83.5% | Valid: loss=1.704, acc= 80.3% | *\n",
      "| Epoch  35, time= 36.6ms/ 11.7ms | Train: loss=1.635, acc= 84.1% | Valid: loss=1.693, acc= 81.5% | *\n",
      "| Epoch  36, time= 36.9ms/ 11.6ms | Train: loss=1.631, acc= 84.2% | Valid: loss=1.684, acc= 81.8% | *\n",
      "tensor(0.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 37.1ms/ 11.7ms | Train: loss=1.676, acc= 80.6% | Valid: loss=1.724, acc= 77.3% |\n",
      "| Epoch  38, time= 36.7ms/ 11.7ms | Train: loss=1.671, acc= 81.5% | Valid: loss=1.729, acc= 78.6% |\n",
      "| Epoch  39, time= 36.3ms/ 11.6ms | Train: loss=1.651, acc= 82.4% | Valid: loss=1.703, acc= 78.6% |\n",
      "| Epoch  40, time= 36.8ms/ 11.7ms | Train: loss=1.625, acc= 84.3% | Valid: loss=1.679, acc= 80.9% | *\n",
      "tensor(0.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 36.8ms/ 12.4ms | Train: loss=1.667, acc= 81.8% | Valid: loss=1.724, acc= 78.2% |\n",
      "| Epoch  42, time= 36.4ms/ 11.6ms | Train: loss=1.618, acc= 84.7% | Valid: loss=1.669, acc= 81.8% | *\n",
      "| Epoch  43, time= 36.8ms/ 11.7ms | Train: loss=1.620, acc= 84.3% | Valid: loss=1.676, acc= 79.8% |\n",
      "| Epoch  44, time= 36.9ms/ 11.8ms | Train: loss=1.637, acc= 82.6% | Valid: loss=1.685, acc= 79.1% |\n",
      "tensor(0.7260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.2ms/ 11.7ms | Train: loss=1.626, acc= 84.6% | Valid: loss=1.679, acc= 81.3% |\n",
      "| Epoch  46, time= 37.1ms/ 11.7ms | Train: loss=1.613, acc= 84.0% | Valid: loss=1.672, acc= 79.7% |\n",
      "| Epoch  47, time= 36.8ms/ 11.6ms | Train: loss=1.623, acc= 83.6% | Valid: loss=1.679, acc= 80.3% | lr=5.6e-03\n",
      "| Epoch  48, time= 36.5ms/ 11.7ms | Train: loss=1.594, acc= 83.7% | Valid: loss=1.651, acc= 80.3% | *\n",
      "tensor(0.6256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 37.1ms/ 11.7ms | Train: loss=1.578, acc= 85.2% | Valid: loss=1.638, acc= 82.4% | *\n",
      "| Epoch  50, time= 37.2ms/ 11.7ms | Train: loss=1.571, acc= 85.0% | Valid: loss=1.630, acc= 81.6% | *\n",
      "| Epoch  51, time= 37.2ms/ 11.7ms | Train: loss=1.587, acc= 83.9% | Valid: loss=1.646, acc= 80.1% |\n",
      "| Epoch  52, time= 37.0ms/ 11.7ms | Train: loss=1.578, acc= 84.5% | Valid: loss=1.636, acc= 80.8% |\n",
      "tensor(0.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.2ms/ 11.8ms | Train: loss=1.613, acc= 83.0% | Valid: loss=1.686, acc= 79.1% |\n",
      "| Epoch  54, time= 36.9ms/ 12.7ms | Train: loss=1.568, acc= 85.4% | Valid: loss=1.641, acc= 82.1% |\n",
      "| Epoch  55, time= 36.8ms/ 11.7ms | Train: loss=1.582, acc= 84.3% | Valid: loss=1.648, acc= 81.4% | lr=1.9e-03\n",
      "| Epoch  56, time= 37.0ms/ 11.7ms | Train: loss=1.559, acc= 85.4% | Valid: loss=1.622, acc= 81.9% | *\n",
      "tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.6ms/ 11.8ms | Train: loss=1.551, acc= 86.1% | Valid: loss=1.619, acc= 82.1% | *\n",
      "| Epoch  58, time= 36.8ms/ 11.8ms | Train: loss=1.546, acc= 86.2% | Valid: loss=1.614, acc= 83.2% | *\n",
      "| Epoch  59, time= 37.1ms/ 11.6ms | Train: loss=1.544, acc= 86.3% | Valid: loss=1.612, acc= 82.6% | *\n",
      "| Epoch  60, time= 36.6ms/ 11.6ms | Train: loss=1.548, acc= 85.8% | Valid: loss=1.609, acc= 82.3% | *\n",
      "tensor(0.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 35.9ms/ 11.8ms | Train: loss=1.541, acc= 86.2% | Valid: loss=1.610, acc= 82.8% |\n",
      "| Epoch  62, time= 37.0ms/ 11.7ms | Train: loss=1.541, acc= 86.4% | Valid: loss=1.610, acc= 82.6% |\n",
      "| Epoch  63, time= 37.2ms/ 11.7ms | Train: loss=1.544, acc= 85.9% | Valid: loss=1.610, acc= 82.4% |\n",
      "| Epoch  64, time= 36.7ms/ 11.7ms | Train: loss=1.545, acc= 85.8% | Valid: loss=1.614, acc= 82.7% |\n",
      "tensor(0.4734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 36.8ms/ 11.6ms | Train: loss=1.539, acc= 86.2% | Valid: loss=1.606, acc= 83.0% | *\n",
      "| Epoch  66, time= 36.7ms/ 11.7ms | Train: loss=1.541, acc= 86.1% | Valid: loss=1.614, acc= 82.2% |\n",
      "| Epoch  67, time= 36.9ms/ 12.4ms | Train: loss=1.538, acc= 86.3% | Valid: loss=1.605, acc= 81.8% | *\n",
      "| Epoch  68, time= 36.2ms/ 11.8ms | Train: loss=1.545, acc= 85.7% | Valid: loss=1.613, acc= 82.0% |\n",
      "tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  69, time= 36.8ms/ 11.7ms | Train: loss=1.536, acc= 86.6% | Valid: loss=1.609, acc= 83.0% |\n",
      "| Epoch  70, time= 36.9ms/ 11.8ms | Train: loss=1.534, acc= 86.6% | Valid: loss=1.607, acc= 83.5% |\n",
      "| Epoch  71, time= 36.7ms/ 11.9ms | Train: loss=1.533, acc= 86.5% | Valid: loss=1.606, acc= 83.6% |\n",
      "| Epoch  72, time= 37.3ms/ 11.6ms | Train: loss=1.537, acc= 85.8% | Valid: loss=1.605, acc= 81.9% | lr=6.2e-04\n",
      "tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  73, time= 36.3ms/ 11.7ms | Train: loss=1.531, acc= 86.2% | Valid: loss=1.600, acc= 82.0% | *\n",
      "| Epoch  74, time= 37.0ms/ 11.7ms | Train: loss=1.533, acc= 86.3% | Valid: loss=1.603, acc= 82.5% |\n",
      "| Epoch  75, time= 36.8ms/ 11.7ms | Train: loss=1.531, acc= 86.5% | Valid: loss=1.600, acc= 82.6% | *\n",
      "| Epoch  76, time= 36.9ms/ 11.7ms | Train: loss=1.526, acc= 86.5% | Valid: loss=1.596, acc= 83.1% | *\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  77, time= 36.4ms/ 11.7ms | Train: loss=1.531, acc= 86.6% | Valid: loss=1.602, acc= 82.5% |\n",
      "| Epoch  78, time= 36.7ms/ 11.8ms | Train: loss=1.528, acc= 86.6% | Valid: loss=1.600, acc= 83.3% |\n",
      "| Epoch  79, time= 37.2ms/ 11.7ms | Train: loss=1.526, acc= 86.6% | Valid: loss=1.598, acc= 83.3% |\n",
      "| Epoch  80, time= 37.2ms/ 12.3ms | Train: loss=1.528, acc= 86.7% | Valid: loss=1.602, acc= 82.4% |\n",
      "tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  81, time= 37.3ms/ 11.7ms | Train: loss=1.528, acc= 86.7% | Valid: loss=1.601, acc= 82.8% | lr=2.1e-04\n",
      "| Epoch  82, time= 36.2ms/ 11.7ms | Train: loss=1.525, acc= 86.6% | Valid: loss=1.598, acc= 82.6% |\n",
      "| Epoch  83, time= 36.3ms/ 11.7ms | Train: loss=1.527, acc= 86.7% | Valid: loss=1.599, acc= 82.6% |\n",
      "| Epoch  84, time= 36.7ms/ 12.0ms | Train: loss=1.530, acc= 86.6% | Valid: loss=1.603, acc= 82.8% |\n",
      "tensor(0.4308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  85, time= 36.9ms/ 11.7ms | Train: loss=1.530, acc= 86.6% | Valid: loss=1.602, acc= 82.8% |\n",
      "| Epoch  86, time= 36.8ms/ 11.7ms | Train: loss=1.528, acc= 86.6% | Valid: loss=1.601, acc= 83.1% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.896, acc= 89.0% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=8.354, acc= 57.5% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=7.298, acc= 90.2% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=8.272, acc= 58.8% <<<\n",
      ">>> Test on task  4 - cifar10-1      : loss=7.397, acc= 82.8% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  5 (cifar100-1)\n",
      "****************************************************************************************************\n",
      "tensor(2.1181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 36.2ms/ 11.8ms | Train: loss=4.072, acc= 36.4% | Valid: loss=4.026, acc= 38.1% | *\n",
      "| Epoch   2, time= 36.8ms/ 11.9ms | Train: loss=3.868, acc= 36.8% | Valid: loss=3.919, acc= 37.0% | *\n",
      "| Epoch   3, time= 36.9ms/ 11.8ms | Train: loss=4.047, acc= 29.9% | Valid: loss=4.116, acc= 27.0% |\n",
      "| Epoch   4, time= 36.4ms/ 11.7ms | Train: loss=4.120, acc= 30.1% | Valid: loss=4.134, acc= 30.0% |\n",
      "tensor(3.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.4774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.8ms/ 11.7ms | Train: loss=4.050, acc= 31.0% | Valid: loss=4.023, acc= 33.6% |\n",
      "| Epoch   6, time= 36.4ms/ 11.7ms | Train: loss=3.425, acc= 46.7% | Valid: loss=3.500, acc= 47.3% | *\n",
      "| Epoch   7, time= 37.6ms/ 11.6ms | Train: loss=3.898, acc= 35.1% | Valid: loss=3.940, acc= 33.8% |\n",
      "| Epoch   8, time= 36.6ms/ 11.8ms | Train: loss=3.461, acc= 44.4% | Valid: loss=3.555, acc= 43.7% |\n",
      "tensor(3.9216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.8615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 36.8ms/ 11.7ms | Train: loss=3.459, acc= 47.3% | Valid: loss=3.514, acc= 47.0% |\n",
      "| Epoch  10, time= 36.9ms/ 11.7ms | Train: loss=3.584, acc= 42.5% | Valid: loss=3.627, acc= 42.3% |\n",
      "| Epoch  11, time= 37.2ms/ 12.1ms | Train: loss=3.402, acc= 46.0% | Valid: loss=3.469, acc= 47.0% | *\n",
      "| Epoch  12, time= 36.8ms/ 11.8ms | Train: loss=3.414, acc= 47.6% | Valid: loss=3.483, acc= 45.0% |\n",
      "tensor(4.0247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.0883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 37.0ms/ 11.6ms | Train: loss=3.482, acc= 43.0% | Valid: loss=3.568, acc= 42.9% |\n",
      "| Epoch  14, time= 36.8ms/ 11.7ms | Train: loss=3.494, acc= 44.5% | Valid: loss=3.548, acc= 43.1% |\n",
      "| Epoch  15, time= 36.9ms/ 12.0ms | Train: loss=3.415, acc= 44.9% | Valid: loss=3.540, acc= 43.1% |\n",
      "| Epoch  16, time= 37.4ms/ 11.7ms | Train: loss=4.022, acc= 29.1% | Valid: loss=4.063, acc= 28.2% | lr=1.7e-02\n",
      "tensor(4.5802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.9ms/ 11.6ms | Train: loss=2.928, acc= 57.3% | Valid: loss=3.099, acc= 54.0% | *\n",
      "| Epoch  18, time= 36.8ms/ 11.7ms | Train: loss=2.937, acc= 56.2% | Valid: loss=3.110, acc= 53.7% |\n",
      "| Epoch  19, time= 36.8ms/ 11.7ms | Train: loss=2.842, acc= 58.3% | Valid: loss=3.034, acc= 54.5% | *\n",
      "| Epoch  20, time= 37.1ms/ 11.7ms | Train: loss=2.774, acc= 61.2% | Valid: loss=2.932, acc= 58.2% | *\n",
      "tensor(2.7414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 36.6ms/ 11.8ms | Train: loss=2.806, acc= 58.8% | Valid: loss=2.989, acc= 56.0% |\n",
      "| Epoch  22, time= 37.2ms/ 11.7ms | Train: loss=2.798, acc= 59.8% | Valid: loss=3.011, acc= 55.6% |\n",
      "| Epoch  23, time= 36.8ms/ 11.6ms | Train: loss=2.828, acc= 57.6% | Valid: loss=3.039, acc= 55.3% |\n",
      "| Epoch  24, time= 37.1ms/ 11.7ms | Train: loss=2.743, acc= 60.9% | Valid: loss=2.926, acc= 58.8% | *\n",
      "tensor(2.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 36.9ms/ 11.7ms | Train: loss=2.735, acc= 61.1% | Valid: loss=2.966, acc= 55.6% |\n",
      "| Epoch  26, time= 36.4ms/ 11.7ms | Train: loss=2.937, acc= 55.7% | Valid: loss=3.111, acc= 53.1% |\n",
      "| Epoch  27, time= 36.8ms/ 11.7ms | Train: loss=2.791, acc= 59.4% | Valid: loss=2.988, acc= 54.3% |\n",
      "| Epoch  28, time= 36.5ms/ 12.1ms | Train: loss=2.813, acc= 58.6% | Valid: loss=3.040, acc= 54.1% |\n",
      "tensor(2.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.8ms/ 11.8ms | Train: loss=2.773, acc= 58.9% | Valid: loss=3.018, acc= 54.9% | lr=5.6e-03\n",
      "| Epoch  30, time= 36.9ms/ 11.7ms | Train: loss=2.553, acc= 64.8% | Valid: loss=2.807, acc= 59.7% | *\n",
      "| Epoch  31, time= 36.8ms/ 11.7ms | Train: loss=2.502, acc= 66.6% | Valid: loss=2.773, acc= 59.6% | *\n",
      "| Epoch  32, time= 36.0ms/ 11.7ms | Train: loss=2.512, acc= 66.2% | Valid: loss=2.801, acc= 59.2% |\n",
      "tensor(2.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 37.6ms/ 11.7ms | Train: loss=2.490, acc= 66.4% | Valid: loss=2.792, acc= 59.5% |\n",
      "| Epoch  34, time= 36.8ms/ 11.6ms | Train: loss=2.501, acc= 66.2% | Valid: loss=2.797, acc= 59.5% |\n",
      "| Epoch  35, time= 36.7ms/ 11.7ms | Train: loss=2.472, acc= 66.9% | Valid: loss=2.790, acc= 58.7% |\n",
      "| Epoch  36, time= 37.0ms/ 11.7ms | Train: loss=2.456, acc= 67.5% | Valid: loss=2.750, acc= 60.1% | *\n",
      "tensor(2.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 36.8ms/ 11.7ms | Train: loss=2.465, acc= 67.1% | Valid: loss=2.763, acc= 60.1% |\n",
      "| Epoch  38, time= 36.5ms/ 11.7ms | Train: loss=2.456, acc= 67.0% | Valid: loss=2.760, acc= 60.2% |\n",
      "| Epoch  39, time= 36.8ms/ 11.6ms | Train: loss=2.452, acc= 67.2% | Valid: loss=2.758, acc= 60.7% |\n",
      "| Epoch  40, time= 36.6ms/ 11.8ms | Train: loss=2.464, acc= 66.7% | Valid: loss=2.769, acc= 60.9% |\n",
      "tensor(1.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 37.0ms/ 12.2ms | Train: loss=2.443, acc= 67.2% | Valid: loss=2.766, acc= 59.6% | lr=1.9e-03\n",
      "| Epoch  42, time= 36.4ms/ 11.7ms | Train: loss=2.393, acc= 68.5% | Valid: loss=2.713, acc= 61.0% | *\n",
      "| Epoch  43, time= 36.1ms/ 11.7ms | Train: loss=2.386, acc= 68.6% | Valid: loss=2.719, acc= 61.4% |\n",
      "| Epoch  44, time= 36.2ms/ 11.7ms | Train: loss=2.383, acc= 69.1% | Valid: loss=2.714, acc= 60.7% |\n",
      "tensor(1.8377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.9ms/ 11.8ms | Train: loss=2.368, acc= 68.9% | Valid: loss=2.706, acc= 61.1% | *\n",
      "| Epoch  46, time= 37.3ms/ 11.8ms | Train: loss=2.380, acc= 68.5% | Valid: loss=2.727, acc= 60.6% |\n",
      "| Epoch  47, time= 36.7ms/ 11.7ms | Train: loss=2.376, acc= 68.9% | Valid: loss=2.710, acc= 61.6% |\n",
      "| Epoch  48, time= 36.4ms/ 11.7ms | Train: loss=2.368, acc= 68.9% | Valid: loss=2.701, acc= 61.5% | *\n",
      "tensor(1.7923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 36.7ms/ 11.7ms | Train: loss=2.370, acc= 69.1% | Valid: loss=2.706, acc= 61.8% |\n",
      "| Epoch  50, time= 36.6ms/ 11.6ms | Train: loss=2.363, acc= 69.6% | Valid: loss=2.706, acc= 60.7% |\n",
      "| Epoch  51, time= 36.7ms/ 11.7ms | Train: loss=2.367, acc= 69.3% | Valid: loss=2.714, acc= 60.9% |\n",
      "| Epoch  52, time= 36.2ms/ 11.6ms | Train: loss=2.356, acc= 69.7% | Valid: loss=2.710, acc= 61.4% |\n",
      "tensor(1.7592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.8ms/ 11.7ms | Train: loss=2.356, acc= 69.5% | Valid: loss=2.700, acc= 60.4% | *\n",
      "| Epoch  54, time= 36.7ms/ 12.4ms | Train: loss=2.347, acc= 69.7% | Valid: loss=2.692, acc= 61.5% | *\n",
      "| Epoch  55, time= 36.6ms/ 11.7ms | Train: loss=2.362, acc= 68.8% | Valid: loss=2.703, acc= 62.0% |\n",
      "| Epoch  56, time= 36.5ms/ 11.7ms | Train: loss=2.333, acc= 70.0% | Valid: loss=2.681, acc= 62.0% | *\n",
      "tensor(1.7360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.6ms/ 11.7ms | Train: loss=2.336, acc= 69.9% | Valid: loss=2.680, acc= 62.1% | *\n",
      "| Epoch  58, time= 36.9ms/ 11.6ms | Train: loss=2.337, acc= 69.9% | Valid: loss=2.693, acc= 61.2% |\n",
      "| Epoch  59, time= 37.1ms/ 11.7ms | Train: loss=2.336, acc= 69.6% | Valid: loss=2.700, acc= 60.8% |\n",
      "| Epoch  60, time= 35.7ms/ 11.7ms | Train: loss=2.331, acc= 69.9% | Valid: loss=2.683, acc= 61.6% |\n",
      "tensor(1.7187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.8ms/ 11.7ms | Train: loss=2.335, acc= 70.1% | Valid: loss=2.695, acc= 60.6% |\n",
      "| Epoch  62, time= 37.0ms/ 11.7ms | Train: loss=2.345, acc= 69.3% | Valid: loss=2.721, acc= 61.4% | lr=6.2e-04\n",
      "| Epoch  63, time= 36.8ms/ 11.7ms | Train: loss=2.317, acc= 69.9% | Valid: loss=2.677, acc= 61.8% | *\n",
      "| Epoch  64, time= 36.8ms/ 11.7ms | Train: loss=2.313, acc= 70.5% | Valid: loss=2.677, acc= 61.5% | *\n",
      "tensor(1.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 37.0ms/ 11.7ms | Train: loss=2.316, acc= 70.4% | Valid: loss=2.681, acc= 61.5% |\n",
      "| Epoch  66, time= 36.7ms/ 11.7ms | Train: loss=2.314, acc= 70.4% | Valid: loss=2.684, acc= 61.5% |\n",
      "| Epoch  67, time= 36.5ms/ 12.5ms | Train: loss=2.313, acc= 70.3% | Valid: loss=2.681, acc= 61.4% |\n",
      "| Epoch  68, time= 36.9ms/ 11.8ms | Train: loss=2.308, acc= 70.3% | Valid: loss=2.684, acc= 61.3% |\n",
      "tensor(1.6590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  69, time= 36.3ms/ 11.8ms | Train: loss=2.310, acc= 70.4% | Valid: loss=2.688, acc= 60.9% | lr=2.1e-04\n",
      "| Epoch  70, time= 36.8ms/ 11.7ms | Train: loss=2.310, acc= 70.6% | Valid: loss=2.682, acc= 61.1% |\n",
      "| Epoch  71, time= 36.3ms/ 11.7ms | Train: loss=2.309, acc= 70.5% | Valid: loss=2.683, acc= 61.4% |\n",
      "| Epoch  72, time= 36.9ms/ 11.8ms | Train: loss=2.309, acc= 70.5% | Valid: loss=2.685, acc= 60.9% |\n",
      "tensor(1.6503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  73, time= 36.6ms/ 11.7ms | Train: loss=2.305, acc= 70.6% | Valid: loss=2.683, acc= 61.3% |\n",
      "| Epoch  74, time= 36.8ms/ 11.7ms | Train: loss=2.305, acc= 70.5% | Valid: loss=2.680, acc= 61.2% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.912, acc= 88.6% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=32.929, acc= 60.0% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=32.067, acc= 87.8% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=32.915, acc= 60.3% <<<\n",
      ">>> Test on task  4 - cifar10-1      : loss=32.162, acc= 81.2% <<<\n",
      ">>> Test on task  5 - cifar100-1     : loss=33.054, acc= 61.6% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  6 (cifar100-2)\n",
      "****************************************************************************************************\n",
      "tensor(2.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 37.3ms/ 11.6ms | Train: loss=4.068, acc= 32.2% | Valid: loss=4.117, acc= 31.7% | *\n",
      "| Epoch   2, time= 37.2ms/ 11.8ms | Train: loss=3.621, acc= 39.5% | Valid: loss=3.731, acc= 36.0% | *\n",
      "| Epoch   3, time= 36.4ms/ 11.8ms | Train: loss=3.488, acc= 40.3% | Valid: loss=3.590, acc= 34.7% | *\n",
      "| Epoch   4, time= 36.2ms/ 11.7ms | Train: loss=3.238, acc= 50.2% | Valid: loss=3.357, acc= 46.0% | *\n",
      "tensor(3.5471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.6193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.4ms/ 11.7ms | Train: loss=3.946, acc= 31.0% | Valid: loss=4.026, acc= 26.9% |\n",
      "| Epoch   6, time= 36.9ms/ 11.8ms | Train: loss=3.809, acc= 35.4% | Valid: loss=3.944, acc= 33.2% |\n",
      "| Epoch   7, time= 36.8ms/ 11.9ms | Train: loss=3.697, acc= 34.1% | Valid: loss=3.808, acc= 29.8% |\n",
      "| Epoch   8, time= 36.6ms/ 11.7ms | Train: loss=3.506, acc= 40.0% | Valid: loss=3.605, acc= 37.4% |\n",
      "tensor(4.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(4.1169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 36.7ms/ 11.8ms | Train: loss=3.442, acc= 42.8% | Valid: loss=3.605, acc= 36.6% | lr=1.7e-02\n",
      "| Epoch  10, time= 37.0ms/ 12.2ms | Train: loss=2.871, acc= 55.3% | Valid: loss=3.023, acc= 48.2% | *\n",
      "| Epoch  11, time= 36.7ms/ 11.7ms | Train: loss=2.795, acc= 57.3% | Valid: loss=2.957, acc= 51.0% | *\n",
      "| Epoch  12, time= 37.0ms/ 11.7ms | Train: loss=2.839, acc= 55.9% | Valid: loss=3.009, acc= 49.1% |\n",
      "tensor(2.5429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 37.0ms/ 11.8ms | Train: loss=3.121, acc= 48.0% | Valid: loss=3.288, acc= 41.4% |\n",
      "| Epoch  14, time= 36.4ms/ 11.8ms | Train: loss=2.915, acc= 53.7% | Valid: loss=3.093, acc= 46.1% |\n",
      "| Epoch  15, time= 36.7ms/ 11.6ms | Train: loss=2.869, acc= 54.4% | Valid: loss=3.031, acc= 47.4% |\n",
      "| Epoch  16, time= 36.5ms/ 11.8ms | Train: loss=2.736, acc= 58.2% | Valid: loss=2.918, acc= 50.5% | *\n",
      "tensor(2.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.6ms/ 11.8ms | Train: loss=2.731, acc= 59.9% | Valid: loss=2.896, acc= 52.0% | *\n",
      "| Epoch  18, time= 36.8ms/ 11.6ms | Train: loss=2.880, acc= 54.7% | Valid: loss=3.054, acc= 48.1% |\n",
      "| Epoch  19, time= 37.1ms/ 11.7ms | Train: loss=2.954, acc= 52.6% | Valid: loss=3.148, acc= 45.4% |\n",
      "| Epoch  20, time= 36.4ms/ 11.7ms | Train: loss=2.844, acc= 54.6% | Valid: loss=3.014, acc= 48.2% |\n",
      "tensor(2.5461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 37.2ms/ 11.7ms | Train: loss=2.777, acc= 56.2% | Valid: loss=2.964, acc= 50.9% |\n",
      "| Epoch  22, time= 36.2ms/ 11.6ms | Train: loss=2.774, acc= 57.8% | Valid: loss=2.960, acc= 51.3% | lr=5.6e-03\n",
      "| Epoch  23, time= 37.1ms/ 12.3ms | Train: loss=2.547, acc= 62.8% | Valid: loss=2.753, acc= 55.4% | *\n",
      "| Epoch  24, time= 36.8ms/ 11.7ms | Train: loss=2.520, acc= 63.1% | Valid: loss=2.730, acc= 54.5% | *\n",
      "tensor(1.9500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 37.1ms/ 11.8ms | Train: loss=2.514, acc= 63.6% | Valid: loss=2.734, acc= 54.7% |\n",
      "| Epoch  26, time= 37.3ms/ 11.7ms | Train: loss=2.497, acc= 63.2% | Valid: loss=2.725, acc= 54.1% | *\n",
      "| Epoch  27, time= 36.9ms/ 12.0ms | Train: loss=2.598, acc= 60.5% | Valid: loss=2.833, acc= 52.2% |\n",
      "| Epoch  28, time= 37.6ms/ 11.6ms | Train: loss=2.500, acc= 62.9% | Valid: loss=2.732, acc= 53.8% |\n",
      "tensor(1.7570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.5ms/ 11.7ms | Train: loss=2.588, acc= 60.0% | Valid: loss=2.815, acc= 52.9% |\n",
      "| Epoch  30, time= 36.5ms/ 11.7ms | Train: loss=2.468, acc= 63.3% | Valid: loss=2.716, acc= 54.9% | *\n",
      "| Epoch  31, time= 36.9ms/ 11.7ms | Train: loss=2.503, acc= 62.4% | Valid: loss=2.752, acc= 53.6% |\n",
      "| Epoch  32, time= 37.4ms/ 11.6ms | Train: loss=2.448, acc= 64.7% | Valid: loss=2.698, acc= 54.3% | *\n",
      "tensor(1.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 36.4ms/ 12.0ms | Train: loss=2.464, acc= 63.5% | Valid: loss=2.710, acc= 54.7% |\n",
      "| Epoch  34, time= 36.6ms/ 11.8ms | Train: loss=2.433, acc= 65.4% | Valid: loss=2.671, acc= 55.2% | *\n",
      "| Epoch  35, time= 36.8ms/ 11.7ms | Train: loss=2.423, acc= 65.0% | Valid: loss=2.675, acc= 55.0% |\n",
      "| Epoch  36, time= 36.8ms/ 11.7ms | Train: loss=2.453, acc= 64.4% | Valid: loss=2.695, acc= 56.0% |\n",
      "tensor(1.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 37.6ms/ 11.7ms | Train: loss=2.447, acc= 63.8% | Valid: loss=2.698, acc= 54.8% |\n",
      "| Epoch  38, time= 36.3ms/ 11.7ms | Train: loss=2.429, acc= 64.4% | Valid: loss=2.696, acc= 54.8% |\n",
      "| Epoch  39, time= 36.6ms/ 11.7ms | Train: loss=2.434, acc= 64.5% | Valid: loss=2.688, acc= 56.6% | lr=1.9e-03\n",
      "| Epoch  40, time= 37.2ms/ 12.2ms | Train: loss=2.360, acc= 66.2% | Valid: loss=2.626, acc= 58.0% | *\n",
      "tensor(1.5280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 36.8ms/ 11.7ms | Train: loss=2.373, acc= 66.1% | Valid: loss=2.644, acc= 57.3% |\n",
      "| Epoch  42, time= 36.7ms/ 11.8ms | Train: loss=2.382, acc= 65.6% | Valid: loss=2.648, acc= 57.1% |\n",
      "| Epoch  43, time= 35.8ms/ 11.7ms | Train: loss=2.354, acc= 66.6% | Valid: loss=2.622, acc= 57.3% | *\n",
      "| Epoch  44, time= 36.8ms/ 11.6ms | Train: loss=2.374, acc= 65.2% | Valid: loss=2.647, acc= 56.3% |\n",
      "tensor(1.4299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 37.3ms/ 11.7ms | Train: loss=2.378, acc= 65.3% | Valid: loss=2.653, acc= 56.9% |\n",
      "| Epoch  46, time= 37.4ms/ 11.7ms | Train: loss=2.342, acc= 66.2% | Valid: loss=2.627, acc= 55.9% |\n",
      "| Epoch  47, time= 36.8ms/ 11.7ms | Train: loss=2.329, acc= 66.7% | Valid: loss=2.603, acc= 57.2% | *\n",
      "| Epoch  48, time= 36.2ms/ 11.8ms | Train: loss=2.329, acc= 67.1% | Valid: loss=2.605, acc= 57.5% |\n",
      "tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 37.1ms/ 11.7ms | Train: loss=2.386, acc= 65.3% | Valid: loss=2.672, acc= 55.6% |\n",
      "| Epoch  50, time= 36.4ms/ 11.8ms | Train: loss=2.342, acc= 66.2% | Valid: loss=2.619, acc= 58.1% |\n",
      "| Epoch  51, time= 37.0ms/ 11.7ms | Train: loss=2.360, acc= 65.9% | Valid: loss=2.636, acc= 57.0% |\n",
      "| Epoch  52, time= 37.0ms/ 11.7ms | Train: loss=2.342, acc= 66.2% | Valid: loss=2.627, acc= 56.4% | lr=6.2e-04\n",
      "tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.9ms/ 12.4ms | Train: loss=2.312, acc= 67.0% | Valid: loss=2.596, acc= 57.4% | *\n",
      "| Epoch  54, time= 36.3ms/ 11.7ms | Train: loss=2.316, acc= 67.1% | Valid: loss=2.598, acc= 57.6% |\n",
      "| Epoch  55, time= 36.8ms/ 11.7ms | Train: loss=2.307, acc= 67.1% | Valid: loss=2.593, acc= 57.8% | *\n",
      "| Epoch  56, time= 36.6ms/ 11.8ms | Train: loss=2.324, acc= 66.8% | Valid: loss=2.606, acc= 57.1% |\n",
      "tensor(1.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.4ms/ 11.8ms | Train: loss=2.324, acc= 66.6% | Valid: loss=2.611, acc= 57.5% |\n",
      "| Epoch  58, time= 37.1ms/ 11.7ms | Train: loss=2.321, acc= 66.9% | Valid: loss=2.605, acc= 57.4% |\n",
      "| Epoch  59, time= 36.9ms/ 11.7ms | Train: loss=2.320, acc= 67.0% | Valid: loss=2.607, acc= 57.6% |\n",
      "| Epoch  60, time= 36.5ms/ 11.7ms | Train: loss=2.302, acc= 67.6% | Valid: loss=2.589, acc= 57.8% | *\n",
      "tensor(1.2738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.5ms/ 11.7ms | Train: loss=2.327, acc= 66.6% | Valid: loss=2.611, acc= 57.7% |\n",
      "| Epoch  62, time= 37.1ms/ 11.7ms | Train: loss=2.316, acc= 67.3% | Valid: loss=2.605, acc= 57.7% |\n",
      "| Epoch  63, time= 36.9ms/ 11.7ms | Train: loss=2.310, acc= 67.2% | Valid: loss=2.598, acc= 58.0% |\n",
      "| Epoch  64, time= 36.4ms/ 11.7ms | Train: loss=2.319, acc= 67.2% | Valid: loss=2.605, acc= 58.1% |\n",
      "tensor(1.2600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 37.2ms/ 11.7ms | Train: loss=2.319, acc= 67.2% | Valid: loss=2.607, acc= 57.8% | lr=2.1e-04\n",
      "| Epoch  66, time= 37.1ms/ 12.3ms | Train: loss=2.308, acc= 67.3% | Valid: loss=2.595, acc= 58.1% |\n",
      "| Epoch  67, time= 36.4ms/ 11.8ms | Train: loss=2.310, acc= 67.2% | Valid: loss=2.597, acc= 58.1% |\n",
      "| Epoch  68, time= 36.9ms/ 11.7ms | Train: loss=2.317, acc= 67.1% | Valid: loss=2.604, acc= 57.4% |\n",
      "tensor(1.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  69, time= 36.9ms/ 11.8ms | Train: loss=2.307, acc= 67.1% | Valid: loss=2.593, acc= 58.1% |\n",
      "| Epoch  70, time= 36.6ms/ 11.8ms | Train: loss=2.301, acc= 67.1% | Valid: loss=2.587, acc= 58.1% | *\n",
      "| Epoch  71, time= 36.9ms/ 11.6ms | Train: loss=2.309, acc= 67.3% | Valid: loss=2.597, acc= 57.8% |\n",
      "| Epoch  72, time= 36.9ms/ 11.7ms | Train: loss=2.319, acc= 66.9% | Valid: loss=2.605, acc= 58.2% |\n",
      "tensor(1.2411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  73, time= 36.7ms/ 11.9ms | Train: loss=2.312, acc= 67.2% | Valid: loss=2.596, acc= 58.8% |\n",
      "| Epoch  74, time= 36.4ms/ 11.7ms | Train: loss=2.310, acc= 67.2% | Valid: loss=2.595, acc= 58.4% |\n",
      "| Epoch  75, time= 37.1ms/ 11.7ms | Train: loss=2.313, acc= 67.3% | Valid: loss=2.598, acc= 58.4% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.942, acc= 87.8% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=26.527, acc= 59.2% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=25.510, acc= 89.7% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=26.497, acc= 58.0% <<<\n",
      ">>> Test on task  4 - cifar10-1      : loss=25.616, acc= 81.4% <<<\n",
      ">>> Test on task  5 - cifar100-1     : loss=26.623, acc= 60.7% <<<\n",
      ">>> Test on task  6 - cifar100-2     : loss=26.487, acc= 59.2% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  7 (cifar10-3)\n",
      "****************************************************************************************************\n",
      "tensor(1.1529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 36.6ms/ 11.7ms | Train: loss=1.978, acc= 84.5% | Valid: loss=2.021, acc= 82.0% | *\n",
      "| Epoch   2, time= 36.5ms/ 11.7ms | Train: loss=1.680, acc= 87.8% | Valid: loss=1.723, acc= 85.9% | *\n",
      "| Epoch   3, time= 36.1ms/ 11.7ms | Train: loss=1.824, acc= 79.0% | Valid: loss=1.889, acc= 76.3% |\n",
      "| Epoch   4, time= 37.3ms/ 11.7ms | Train: loss=1.964, acc= 68.0% | Valid: loss=1.976, acc= 66.2% |\n",
      "tensor(1.5643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.8ms/ 11.7ms | Train: loss=1.612, acc= 89.0% | Valid: loss=1.644, acc= 88.0% | *\n",
      "| Epoch   6, time= 36.7ms/ 11.7ms | Train: loss=1.541, acc= 91.1% | Valid: loss=1.567, acc= 90.7% | *\n",
      "| Epoch   7, time= 36.8ms/ 11.8ms | Train: loss=2.189, acc= 58.0% | Valid: loss=2.213, acc= 58.4% |\n",
      "| Epoch   8, time= 36.4ms/ 11.8ms | Train: loss=1.699, acc= 82.0% | Valid: loss=1.753, acc= 79.7% |\n",
      "tensor(1.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 37.0ms/ 11.8ms | Train: loss=1.691, acc= 82.0% | Valid: loss=1.714, acc= 81.1% |\n",
      "| Epoch  10, time= 36.3ms/ 11.7ms | Train: loss=1.543, acc= 90.2% | Valid: loss=1.590, acc= 88.4% |\n",
      "| Epoch  11, time= 36.8ms/ 11.7ms | Train: loss=1.694, acc= 82.5% | Valid: loss=1.764, acc= 79.6% | lr=1.7e-02\n",
      "| Epoch  12, time= 36.7ms/ 12.1ms | Train: loss=1.454, acc= 93.6% | Valid: loss=1.463, acc= 93.5% | *\n",
      "tensor(0.9510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 37.1ms/ 11.7ms | Train: loss=1.446, acc= 94.2% | Valid: loss=1.455, acc= 93.9% | *\n",
      "| Epoch  14, time= 37.1ms/ 11.7ms | Train: loss=1.448, acc= 94.0% | Valid: loss=1.464, acc= 93.8% |\n",
      "| Epoch  15, time= 36.8ms/ 11.7ms | Train: loss=1.437, acc= 94.3% | Valid: loss=1.460, acc= 92.8% |\n",
      "| Epoch  16, time= 36.4ms/ 11.8ms | Train: loss=1.657, acc= 83.3% | Valid: loss=1.673, acc= 83.1% |\n",
      "tensor(0.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 37.4ms/ 11.7ms | Train: loss=1.510, acc= 89.6% | Valid: loss=1.531, acc= 89.9% |\n",
      "| Epoch  18, time= 36.6ms/ 11.8ms | Train: loss=1.425, acc= 94.4% | Valid: loss=1.451, acc= 93.7% | *\n",
      "| Epoch  19, time= 37.1ms/ 11.8ms | Train: loss=1.474, acc= 91.6% | Valid: loss=1.493, acc= 91.1% |\n",
      "| Epoch  20, time= 36.5ms/ 11.7ms | Train: loss=1.436, acc= 92.9% | Valid: loss=1.446, acc= 92.7% | *\n",
      "tensor(0.7804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 37.2ms/ 11.8ms | Train: loss=1.557, acc= 87.3% | Valid: loss=1.575, acc= 86.6% |\n",
      "| Epoch  22, time= 36.2ms/ 11.8ms | Train: loss=1.416, acc= 94.5% | Valid: loss=1.443, acc= 93.0% | *\n",
      "| Epoch  23, time= 36.6ms/ 11.7ms | Train: loss=1.577, acc= 87.0% | Valid: loss=1.617, acc= 86.0% |\n",
      "| Epoch  24, time= 36.4ms/ 11.8ms | Train: loss=2.112, acc= 66.5% | Valid: loss=2.137, acc= 65.9% |\n",
      "tensor(0.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 36.7ms/ 12.3ms | Train: loss=1.423, acc= 93.9% | Valid: loss=1.447, acc= 92.7% |\n",
      "| Epoch  26, time= 36.4ms/ 11.7ms | Train: loss=1.436, acc= 93.2% | Valid: loss=1.461, acc= 92.3% |\n",
      "| Epoch  27, time= 36.6ms/ 11.6ms | Train: loss=1.422, acc= 94.2% | Valid: loss=1.451, acc= 92.7% | lr=5.6e-03\n",
      "| Epoch  28, time= 36.8ms/ 11.6ms | Train: loss=1.372, acc= 95.0% | Valid: loss=1.397, acc= 94.4% | *\n",
      "tensor(0.6347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.9ms/ 11.7ms | Train: loss=1.458, acc= 93.2% | Valid: loss=1.487, acc= 91.9% |\n",
      "| Epoch  30, time= 37.2ms/ 11.6ms | Train: loss=1.355, acc= 95.4% | Valid: loss=1.369, acc= 94.7% | *\n",
      "| Epoch  31, time= 37.0ms/ 11.7ms | Train: loss=1.371, acc= 94.5% | Valid: loss=1.380, acc= 93.9% |\n",
      "| Epoch  32, time= 37.0ms/ 11.8ms | Train: loss=1.348, acc= 95.6% | Valid: loss=1.372, acc= 94.8% |\n",
      "tensor(0.5308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 36.8ms/ 11.7ms | Train: loss=1.364, acc= 95.1% | Valid: loss=1.375, acc= 94.5% |\n",
      "| Epoch  34, time= 37.1ms/ 11.7ms | Train: loss=1.347, acc= 95.6% | Valid: loss=1.370, acc= 94.7% |\n",
      "| Epoch  35, time= 36.9ms/ 11.7ms | Train: loss=1.351, acc= 95.7% | Valid: loss=1.363, acc= 94.9% | *\n",
      "| Epoch  36, time= 36.6ms/ 11.7ms | Train: loss=1.338, acc= 95.9% | Valid: loss=1.355, acc= 95.1% | *\n",
      "tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 36.8ms/ 11.8ms | Train: loss=1.352, acc= 95.1% | Valid: loss=1.361, acc= 94.1% |\n",
      "| Epoch  38, time= 37.1ms/ 12.2ms | Train: loss=1.361, acc= 94.5% | Valid: loss=1.359, acc= 94.2% |\n",
      "| Epoch  39, time= 35.8ms/ 11.8ms | Train: loss=1.367, acc= 94.3% | Valid: loss=1.375, acc= 94.7% |\n",
      "| Epoch  40, time= 36.8ms/ 11.8ms | Train: loss=1.332, acc= 96.1% | Valid: loss=1.344, acc= 95.4% | *\n",
      "tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 36.9ms/ 11.7ms | Train: loss=1.371, acc= 94.2% | Valid: loss=1.377, acc= 94.0% |\n",
      "| Epoch  42, time= 36.6ms/ 11.9ms | Train: loss=1.365, acc= 94.3% | Valid: loss=1.375, acc= 94.0% |\n",
      "| Epoch  43, time= 37.0ms/ 11.8ms | Train: loss=1.348, acc= 95.1% | Valid: loss=1.371, acc= 94.4% |\n",
      "| Epoch  44, time= 37.0ms/ 11.9ms | Train: loss=1.340, acc= 95.7% | Valid: loss=1.353, acc= 95.2% |\n",
      "tensor(0.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.9ms/ 11.8ms | Train: loss=1.356, acc= 94.5% | Valid: loss=1.372, acc= 94.1% | lr=1.9e-03\n",
      "| Epoch  46, time= 36.9ms/ 12.3ms | Train: loss=1.315, acc= 96.2% | Valid: loss=1.331, acc= 95.2% | *\n",
      "| Epoch  47, time= 36.9ms/ 11.7ms | Train: loss=1.329, acc= 95.4% | Valid: loss=1.340, acc= 94.7% |\n",
      "| Epoch  48, time= 36.6ms/ 11.7ms | Train: loss=1.317, acc= 96.1% | Valid: loss=1.333, acc= 95.0% |\n",
      "tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 36.3ms/ 11.8ms | Train: loss=1.312, acc= 96.1% | Valid: loss=1.331, acc= 95.4% |\n",
      "| Epoch  50, time= 37.1ms/ 11.7ms | Train: loss=1.338, acc= 95.1% | Valid: loss=1.347, acc= 94.8% |\n",
      "| Epoch  51, time= 36.9ms/ 12.0ms | Train: loss=1.311, acc= 96.1% | Valid: loss=1.326, acc= 95.0% | *\n",
      "| Epoch  52, time= 37.1ms/ 12.4ms | Train: loss=1.319, acc= 95.9% | Valid: loss=1.333, acc= 94.8% |\n",
      "tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 38.1ms/ 11.7ms | Train: loss=1.325, acc= 95.9% | Valid: loss=1.334, acc= 95.4% |\n",
      "| Epoch  54, time= 37.0ms/ 11.8ms | Train: loss=1.326, acc= 95.9% | Valid: loss=1.333, acc= 95.7% |\n",
      "| Epoch  55, time= 36.4ms/ 12.4ms | Train: loss=1.319, acc= 95.9% | Valid: loss=1.330, acc= 95.2% |\n",
      "| Epoch  56, time= 36.6ms/ 11.8ms | Train: loss=1.369, acc= 94.0% | Valid: loss=1.373, acc= 93.2% | lr=6.2e-04\n",
      "tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.6ms/ 11.7ms | Train: loss=1.322, acc= 95.9% | Valid: loss=1.333, acc= 95.5% |\n",
      "| Epoch  58, time= 36.8ms/ 11.7ms | Train: loss=1.322, acc= 96.0% | Valid: loss=1.333, acc= 95.6% |\n",
      "| Epoch  59, time= 36.5ms/ 11.7ms | Train: loss=1.318, acc= 96.1% | Valid: loss=1.331, acc= 95.4% |\n",
      "| Epoch  60, time= 37.3ms/ 11.8ms | Train: loss=1.317, acc= 96.0% | Valid: loss=1.328, acc= 95.6% |\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.7ms/ 11.7ms | Train: loss=1.319, acc= 96.0% | Valid: loss=1.329, acc= 95.3% | lr=2.1e-04\n",
      "| Epoch  62, time= 36.6ms/ 11.7ms | Train: loss=1.312, acc= 96.1% | Valid: loss=1.324, acc= 95.6% | *\n",
      "| Epoch  63, time= 37.0ms/ 11.8ms | Train: loss=1.313, acc= 96.2% | Valid: loss=1.324, acc= 95.5% | *\n",
      "| Epoch  64, time= 36.4ms/ 11.7ms | Train: loss=1.318, acc= 96.0% | Valid: loss=1.328, acc= 95.7% |\n",
      "tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 36.6ms/ 11.7ms | Train: loss=1.314, acc= 96.0% | Valid: loss=1.325, acc= 95.7% |\n",
      "| Epoch  66, time= 36.8ms/ 11.8ms | Train: loss=1.314, acc= 96.2% | Valid: loss=1.326, acc= 95.5% |\n",
      "| Epoch  67, time= 36.9ms/ 11.6ms | Train: loss=1.322, acc= 95.9% | Valid: loss=1.331, acc= 95.4% |\n",
      "| Epoch  68, time= 36.2ms/ 12.2ms | Train: loss=1.319, acc= 96.0% | Valid: loss=1.329, acc= 95.3% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.960, acc= 87.2% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=9.927, acc= 57.9% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=8.844, acc= 88.2% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=9.957, acc= 54.3% <<<\n",
      ">>> Test on task  4 - cifar10-1      : loss=9.002, acc= 79.4% <<<\n",
      ">>> Test on task  5 - cifar100-1     : loss=10.021, acc= 59.5% <<<\n",
      ">>> Test on task  6 - cifar100-2     : loss=9.829, acc= 58.3% <<<\n",
      ">>> Test on task  7 - cifar10-3      : loss=8.636, acc= 95.1% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  8 (cifar10-0)\n",
      "****************************************************************************************************\n",
      "tensor(1.1015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 36.9ms/ 11.7ms | Train: loss=2.964, acc= 53.5% | Valid: loss=2.900, acc= 55.5% | *\n",
      "| Epoch   2, time= 36.4ms/ 11.8ms | Train: loss=1.894, acc= 86.7% | Valid: loss=1.896, acc= 87.1% | *\n",
      "| Epoch   3, time= 36.6ms/ 11.7ms | Train: loss=1.856, acc= 86.4% | Valid: loss=1.842, acc= 87.2% | *\n",
      "| Epoch   4, time= 37.3ms/ 12.8ms | Train: loss=2.021, acc= 77.4% | Valid: loss=2.048, acc= 75.9% |\n",
      "tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 36.7ms/ 11.7ms | Train: loss=1.815, acc= 86.5% | Valid: loss=1.800, acc= 87.4% | *\n",
      "| Epoch   6, time= 37.0ms/ 11.8ms | Train: loss=1.848, acc= 84.9% | Valid: loss=1.862, acc= 84.0% |\n",
      "| Epoch   7, time= 36.8ms/ 11.8ms | Train: loss=1.766, acc= 87.5% | Valid: loss=1.768, acc= 88.6% | *\n",
      "| Epoch   8, time= 36.3ms/ 11.8ms | Train: loss=1.930, acc= 79.3% | Valid: loss=1.950, acc= 77.6% |\n",
      "tensor(1.4325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 37.8ms/ 11.8ms | Train: loss=1.975, acc= 76.5% | Valid: loss=1.996, acc= 75.1% |\n",
      "| Epoch  10, time= 36.6ms/ 11.8ms | Train: loss=1.831, acc= 85.6% | Valid: loss=1.830, acc= 86.9% |\n",
      "| Epoch  11, time= 36.6ms/ 11.7ms | Train: loss=1.809, acc= 83.5% | Valid: loss=1.821, acc= 82.0% |\n",
      "| Epoch  12, time= 36.5ms/ 11.7ms | Train: loss=1.915, acc= 76.8% | Valid: loss=1.939, acc= 75.4% | lr=1.7e-02\n",
      "tensor(1.4469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 37.4ms/ 11.7ms | Train: loss=1.690, acc= 87.7% | Valid: loss=1.698, acc= 87.0% | *\n",
      "| Epoch  14, time= 36.5ms/ 11.8ms | Train: loss=1.637, acc= 90.0% | Valid: loss=1.635, acc= 89.5% | *\n",
      "| Epoch  15, time= 36.6ms/ 11.7ms | Train: loss=1.607, acc= 91.0% | Valid: loss=1.612, acc= 90.3% | *\n",
      "| Epoch  16, time= 35.9ms/ 11.8ms | Train: loss=1.605, acc= 90.4% | Valid: loss=1.607, acc= 89.9% | *\n",
      "tensor(0.8052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.9ms/ 12.2ms | Train: loss=1.798, acc= 81.8% | Valid: loss=1.818, acc= 80.5% |\n",
      "| Epoch  18, time= 36.2ms/ 11.9ms | Train: loss=1.646, acc= 88.1% | Valid: loss=1.655, acc= 87.7% |\n",
      "| Epoch  19, time= 36.9ms/ 11.8ms | Train: loss=1.578, acc= 91.4% | Valid: loss=1.579, acc= 91.9% | *\n",
      "| Epoch  20, time= 36.9ms/ 11.7ms | Train: loss=1.572, acc= 91.4% | Valid: loss=1.575, acc= 91.4% | *\n",
      "tensor(0.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 37.0ms/ 12.1ms | Train: loss=1.636, acc= 88.2% | Valid: loss=1.646, acc= 87.6% |\n",
      "| Epoch  22, time= 37.8ms/ 11.7ms | Train: loss=1.584, acc= 90.4% | Valid: loss=1.590, acc= 89.7% |\n",
      "| Epoch  23, time= 36.0ms/ 11.7ms | Train: loss=1.550, acc= 91.7% | Valid: loss=1.551, acc= 92.1% | *\n",
      "| Epoch  24, time= 36.9ms/ 11.8ms | Train: loss=1.703, acc= 85.1% | Valid: loss=1.711, acc= 84.2% |\n",
      "tensor(0.8097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 37.1ms/ 11.7ms | Train: loss=1.546, acc= 91.4% | Valid: loss=1.537, acc= 92.1% | *\n",
      "| Epoch  26, time= 37.2ms/ 11.8ms | Train: loss=1.534, acc= 92.2% | Valid: loss=1.539, acc= 92.1% |\n",
      "| Epoch  27, time= 36.7ms/ 11.7ms | Train: loss=1.694, acc= 84.6% | Valid: loss=1.668, acc= 86.3% |\n",
      "| Epoch  28, time= 36.7ms/ 11.7ms | Train: loss=1.796, acc= 81.5% | Valid: loss=1.822, acc= 79.7% |\n",
      "tensor(0.8829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.7ms/ 11.7ms | Train: loss=1.513, acc= 91.8% | Valid: loss=1.515, acc= 92.2% | *\n",
      "| Epoch  30, time= 37.2ms/ 11.6ms | Train: loss=1.609, acc= 87.8% | Valid: loss=1.622, acc= 86.8% |\n",
      "| Epoch  31, time= 36.9ms/ 11.7ms | Train: loss=1.686, acc= 85.0% | Valid: loss=1.698, acc= 83.8% |\n",
      "| Epoch  32, time= 37.0ms/ 11.7ms | Train: loss=1.623, acc= 87.0% | Valid: loss=1.604, acc= 88.2% |\n",
      "tensor(0.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 36.6ms/ 11.7ms | Train: loss=1.565, acc= 89.2% | Valid: loss=1.577, acc= 88.5% |\n",
      "| Epoch  34, time= 36.4ms/ 12.5ms | Train: loss=1.558, acc= 89.7% | Valid: loss=1.570, acc= 89.9% | lr=5.6e-03\n",
      "| Epoch  35, time= 36.8ms/ 11.7ms | Train: loss=1.492, acc= 92.1% | Valid: loss=1.492, acc= 91.8% | *\n",
      "| Epoch  36, time= 36.4ms/ 11.7ms | Train: loss=1.543, acc= 90.3% | Valid: loss=1.548, acc= 88.9% |\n",
      "tensor(0.6581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 36.6ms/ 11.7ms | Train: loss=1.491, acc= 92.3% | Valid: loss=1.491, acc= 92.2% | *\n",
      "| Epoch  38, time= 36.9ms/ 11.8ms | Train: loss=1.482, acc= 92.6% | Valid: loss=1.484, acc= 92.7% | *\n",
      "| Epoch  39, time= 36.9ms/ 11.7ms | Train: loss=1.480, acc= 92.6% | Valid: loss=1.483, acc= 91.9% | *\n",
      "| Epoch  40, time= 36.4ms/ 11.7ms | Train: loss=1.486, acc= 92.5% | Valid: loss=1.486, acc= 92.3% |\n",
      "tensor(0.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 36.8ms/ 11.6ms | Train: loss=1.470, acc= 92.7% | Valid: loss=1.469, acc= 92.4% | *\n",
      "| Epoch  42, time= 36.5ms/ 11.7ms | Train: loss=1.458, acc= 93.2% | Valid: loss=1.462, acc= 93.2% | *\n",
      "| Epoch  43, time= 37.4ms/ 11.7ms | Train: loss=1.455, acc= 93.2% | Valid: loss=1.460, acc= 93.1% | *\n",
      "| Epoch  44, time= 36.4ms/ 11.7ms | Train: loss=1.455, acc= 93.2% | Valid: loss=1.458, acc= 93.4% | *\n",
      "tensor(0.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.3ms/ 11.8ms | Train: loss=1.523, acc= 90.5% | Valid: loss=1.533, acc= 89.5% |\n",
      "| Epoch  46, time= 36.2ms/ 11.8ms | Train: loss=1.445, acc= 93.3% | Valid: loss=1.452, acc= 92.7% | *\n",
      "| Epoch  47, time= 36.1ms/ 12.7ms | Train: loss=1.448, acc= 93.1% | Valid: loss=1.458, acc= 93.2% |\n",
      "| Epoch  48, time= 36.4ms/ 11.6ms | Train: loss=1.481, acc= 91.9% | Valid: loss=1.488, acc= 91.5% |\n",
      "tensor(0.5604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 36.8ms/ 11.8ms | Train: loss=1.458, acc= 92.7% | Valid: loss=1.463, acc= 91.9% |\n",
      "| Epoch  50, time= 36.9ms/ 11.7ms | Train: loss=1.501, acc= 90.9% | Valid: loss=1.512, acc= 89.7% |\n",
      "| Epoch  51, time= 36.7ms/ 11.7ms | Train: loss=1.461, acc= 92.4% | Valid: loss=1.466, acc= 91.5% | lr=1.9e-03\n",
      "| Epoch  52, time= 37.2ms/ 11.7ms | Train: loss=1.446, acc= 93.0% | Valid: loss=1.452, acc= 92.1% | *\n",
      "tensor(0.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.9ms/ 11.8ms | Train: loss=1.439, acc= 93.2% | Valid: loss=1.442, acc= 93.0% | *\n",
      "| Epoch  54, time= 36.5ms/ 11.7ms | Train: loss=1.440, acc= 93.3% | Valid: loss=1.445, acc= 92.7% |\n",
      "| Epoch  55, time= 36.3ms/ 11.7ms | Train: loss=1.445, acc= 92.9% | Valid: loss=1.452, acc= 92.0% |\n",
      "| Epoch  56, time= 37.2ms/ 11.8ms | Train: loss=1.447, acc= 93.2% | Valid: loss=1.452, acc= 92.4% |\n",
      "tensor(0.4887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.7ms/ 11.7ms | Train: loss=1.465, acc= 92.2% | Valid: loss=1.471, acc= 91.1% |\n",
      "| Epoch  58, time= 36.6ms/ 11.7ms | Train: loss=1.456, acc= 92.6% | Valid: loss=1.463, acc= 91.4% | lr=6.2e-04\n",
      "| Epoch  59, time= 36.4ms/ 11.7ms | Train: loss=1.437, acc= 93.3% | Valid: loss=1.445, acc= 92.8% |\n",
      "| Epoch  60, time= 36.5ms/ 12.5ms | Train: loss=1.440, acc= 93.1% | Valid: loss=1.447, acc= 92.5% |\n",
      "tensor(0.4715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.9ms/ 11.7ms | Train: loss=1.441, acc= 93.3% | Valid: loss=1.449, acc= 92.5% |\n",
      "| Epoch  62, time= 37.1ms/ 11.6ms | Train: loss=1.441, acc= 93.2% | Valid: loss=1.450, acc= 92.2% |\n",
      "| Epoch  63, time= 36.6ms/ 11.8ms | Train: loss=1.439, acc= 93.1% | Valid: loss=1.448, acc= 92.1% | lr=2.1e-04\n",
      "| Epoch  64, time= 36.4ms/ 11.7ms | Train: loss=1.442, acc= 93.1% | Valid: loss=1.450, acc= 92.1% |\n",
      "tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  65, time= 37.8ms/ 11.8ms | Train: loss=1.446, acc= 93.0% | Valid: loss=1.454, acc= 92.1% |\n",
      "| Epoch  66, time= 36.7ms/ 11.8ms | Train: loss=1.437, acc= 93.3% | Valid: loss=1.445, acc= 92.4% |\n",
      "| Epoch  67, time= 36.9ms/ 11.6ms | Train: loss=1.438, acc= 93.2% | Valid: loss=1.445, acc= 92.4% |\n",
      "| Epoch  68, time= 36.6ms/ 11.7ms | Train: loss=1.436, acc= 93.3% | Valid: loss=1.444, acc= 92.8% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.972, acc= 86.6% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=10.116, acc= 58.9% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=9.211, acc= 88.1% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=10.188, acc= 57.8% <<<\n",
      ">>> Test on task  4 - cifar10-1      : loss=9.344, acc= 79.8% <<<\n",
      ">>> Test on task  5 - cifar100-1     : loss=10.266, acc= 61.6% <<<\n",
      ">>> Test on task  6 - cifar100-2     : loss=10.267, acc= 57.1% <<<\n",
      ">>> Test on task  7 - cifar10-3      : loss=9.073, acc= 92.3% <<<\n",
      ">>> Test on task  8 - cifar10-0      : loss=9.127, acc= 92.8% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Task  9 (cifar100-0)\n",
      "****************************************************************************************************\n",
      "tensor(1.8376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   1, time= 37.1ms/ 11.8ms | Train: loss=3.895, acc= 32.4% | Valid: loss=3.988, acc= 30.1% | *\n",
      "| Epoch   2, time= 36.6ms/ 11.7ms | Train: loss=3.510, acc= 41.2% | Valid: loss=3.612, acc= 39.4% | *\n",
      "| Epoch   3, time= 37.2ms/ 11.8ms | Train: loss=3.699, acc= 34.5% | Valid: loss=3.781, acc= 31.9% |\n",
      "| Epoch   4, time= 36.4ms/ 11.7ms | Train: loss=3.497, acc= 37.3% | Valid: loss=3.688, acc= 32.2% |\n",
      "tensor(3.2107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.2622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   5, time= 37.1ms/ 11.7ms | Train: loss=3.724, acc= 34.9% | Valid: loss=3.859, acc= 31.0% |\n",
      "| Epoch   6, time= 36.7ms/ 11.7ms | Train: loss=3.757, acc= 31.3% | Valid: loss=3.948, acc= 26.9% |\n",
      "| Epoch   7, time= 36.3ms/ 11.7ms | Train: loss=3.506, acc= 39.9% | Valid: loss=3.615, acc= 36.7% | lr=1.7e-02\n",
      "| Epoch   8, time= 36.1ms/ 11.7ms | Train: loss=3.018, acc= 53.2% | Valid: loss=3.211, acc= 47.3% | *\n",
      "tensor(2.7490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch   9, time= 37.3ms/ 11.7ms | Train: loss=2.934, acc= 55.2% | Valid: loss=3.148, acc= 48.3% | *\n",
      "| Epoch  10, time= 36.8ms/ 11.7ms | Train: loss=2.955, acc= 54.4% | Valid: loss=3.178, acc= 47.6% |\n",
      "| Epoch  11, time= 36.3ms/ 11.7ms | Train: loss=2.941, acc= 53.0% | Valid: loss=3.185, acc= 46.7% |\n",
      "| Epoch  12, time= 36.5ms/ 11.8ms | Train: loss=2.943, acc= 53.2% | Valid: loss=3.127, acc= 48.5% | *\n",
      "tensor(2.4594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  13, time= 36.7ms/ 12.5ms | Train: loss=2.901, acc= 55.7% | Valid: loss=3.135, acc= 48.1% |\n",
      "| Epoch  14, time= 36.8ms/ 11.7ms | Train: loss=2.880, acc= 56.5% | Valid: loss=3.104, acc= 49.5% | *\n",
      "| Epoch  15, time= 37.1ms/ 11.7ms | Train: loss=2.744, acc= 60.0% | Valid: loss=3.007, acc= 51.3% | *\n",
      "| Epoch  16, time= 36.2ms/ 11.8ms | Train: loss=2.904, acc= 54.5% | Valid: loss=3.124, acc= 47.8% |\n",
      "tensor(2.5051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  17, time= 36.4ms/ 11.7ms | Train: loss=2.765, acc= 58.7% | Valid: loss=3.005, acc= 51.3% | *\n",
      "| Epoch  18, time= 36.8ms/ 11.7ms | Train: loss=3.155, acc= 47.7% | Valid: loss=3.446, acc= 42.7% |\n",
      "| Epoch  19, time= 37.2ms/ 11.7ms | Train: loss=2.834, acc= 57.1% | Valid: loss=3.137, acc= 49.6% |\n",
      "| Epoch  20, time= 36.7ms/ 11.8ms | Train: loss=2.725, acc= 60.5% | Valid: loss=2.969, acc= 52.8% | *\n",
      "tensor(2.5153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  21, time= 36.4ms/ 11.7ms | Train: loss=2.747, acc= 58.4% | Valid: loss=3.000, acc= 51.4% |\n",
      "| Epoch  22, time= 37.6ms/ 11.7ms | Train: loss=2.723, acc= 59.9% | Valid: loss=3.001, acc= 53.3% |\n",
      "| Epoch  23, time= 37.1ms/ 11.6ms | Train: loss=2.973, acc= 53.3% | Valid: loss=3.290, acc= 47.1% |\n",
      "| Epoch  24, time= 36.7ms/ 11.7ms | Train: loss=2.956, acc= 54.0% | Valid: loss=3.174, acc= 46.6% |\n",
      "tensor(2.6490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  25, time= 36.2ms/ 11.7ms | Train: loss=2.782, acc= 56.9% | Valid: loss=3.074, acc= 47.7% | lr=5.6e-03\n",
      "| Epoch  26, time= 37.0ms/ 12.0ms | Train: loss=2.664, acc= 60.3% | Valid: loss=2.978, acc= 51.6% |\n",
      "| Epoch  27, time= 36.2ms/ 11.7ms | Train: loss=2.528, acc= 65.2% | Valid: loss=2.855, acc= 56.3% | *\n",
      "| Epoch  28, time= 36.6ms/ 11.7ms | Train: loss=2.534, acc= 64.5% | Valid: loss=2.864, acc= 55.4% |\n",
      "tensor(2.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  29, time= 36.5ms/ 12.6ms | Train: loss=2.535, acc= 64.0% | Valid: loss=2.882, acc= 54.3% |\n",
      "| Epoch  30, time= 36.5ms/ 11.7ms | Train: loss=2.518, acc= 65.2% | Valid: loss=2.851, acc= 55.2% | *\n",
      "| Epoch  31, time= 37.0ms/ 11.6ms | Train: loss=2.496, acc= 65.4% | Valid: loss=2.862, acc= 54.5% |\n",
      "| Epoch  32, time= 36.7ms/ 11.7ms | Train: loss=2.515, acc= 63.9% | Valid: loss=2.863, acc= 54.5% |\n",
      "tensor(1.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  33, time= 36.6ms/ 11.8ms | Train: loss=2.471, acc= 65.9% | Valid: loss=2.828, acc= 55.7% | *\n",
      "| Epoch  34, time= 36.5ms/ 11.6ms | Train: loss=2.487, acc= 64.6% | Valid: loss=2.841, acc= 54.6% |\n",
      "| Epoch  35, time= 37.2ms/ 11.7ms | Train: loss=2.504, acc= 65.0% | Valid: loss=2.842, acc= 56.6% |\n",
      "| Epoch  36, time= 36.6ms/ 11.7ms | Train: loss=2.536, acc= 63.9% | Valid: loss=2.925, acc= 53.6% |\n",
      "tensor(1.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  37, time= 36.8ms/ 11.7ms | Train: loss=2.484, acc= 65.0% | Valid: loss=2.829, acc= 53.9% |\n",
      "| Epoch  38, time= 36.2ms/ 11.7ms | Train: loss=2.472, acc= 65.5% | Valid: loss=2.857, acc= 55.6% | lr=1.9e-03\n",
      "| Epoch  39, time= 36.9ms/ 12.0ms | Train: loss=2.394, acc= 67.8% | Valid: loss=2.777, acc= 56.6% | *\n",
      "| Epoch  40, time= 36.4ms/ 11.6ms | Train: loss=2.392, acc= 67.7% | Valid: loss=2.793, acc= 57.1% |\n",
      "tensor(1.8022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  41, time= 36.4ms/ 11.8ms | Train: loss=2.378, acc= 68.1% | Valid: loss=2.780, acc= 57.0% |\n",
      "| Epoch  42, time= 36.7ms/ 11.7ms | Train: loss=2.376, acc= 67.8% | Valid: loss=2.769, acc= 56.8% | *\n",
      "| Epoch  43, time= 36.7ms/ 12.1ms | Train: loss=2.381, acc= 67.7% | Valid: loss=2.781, acc= 56.7% |\n",
      "| Epoch  44, time= 36.6ms/ 11.7ms | Train: loss=2.374, acc= 67.5% | Valid: loss=2.766, acc= 58.1% | *\n",
      "tensor(1.7468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  45, time= 36.7ms/ 11.7ms | Train: loss=2.365, acc= 68.0% | Valid: loss=2.761, acc= 57.4% | *\n",
      "| Epoch  46, time= 36.5ms/ 11.8ms | Train: loss=2.349, acc= 68.1% | Valid: loss=2.753, acc= 57.3% | *\n",
      "| Epoch  47, time= 36.7ms/ 11.7ms | Train: loss=2.355, acc= 68.3% | Valid: loss=2.746, acc= 57.6% | *\n",
      "| Epoch  48, time= 36.9ms/ 11.6ms | Train: loss=2.348, acc= 68.4% | Valid: loss=2.752, acc= 56.9% |\n",
      "tensor(1.7138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  49, time= 37.3ms/ 11.8ms | Train: loss=2.380, acc= 67.1% | Valid: loss=2.782, acc= 55.7% |\n",
      "| Epoch  50, time= 36.3ms/ 11.6ms | Train: loss=2.343, acc= 68.3% | Valid: loss=2.755, acc= 57.1% |\n",
      "| Epoch  51, time= 36.6ms/ 11.7ms | Train: loss=2.342, acc= 68.7% | Valid: loss=2.752, acc= 57.5% |\n",
      "| Epoch  52, time= 37.0ms/ 11.8ms | Train: loss=2.358, acc= 68.3% | Valid: loss=2.750, acc= 57.4% | lr=6.2e-04\n",
      "tensor(1.6853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  53, time= 36.9ms/ 11.7ms | Train: loss=2.327, acc= 68.9% | Valid: loss=2.735, acc= 57.3% | *\n",
      "| Epoch  54, time= 37.2ms/ 11.7ms | Train: loss=2.320, acc= 69.2% | Valid: loss=2.728, acc= 57.8% | *\n",
      "| Epoch  55, time= 36.1ms/ 11.6ms | Train: loss=2.338, acc= 69.0% | Valid: loss=2.748, acc= 57.1% |\n",
      "| Epoch  56, time= 37.1ms/ 12.3ms | Train: loss=2.335, acc= 68.7% | Valid: loss=2.739, acc= 57.4% |\n",
      "tensor(1.6455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  57, time= 36.7ms/ 11.7ms | Train: loss=2.321, acc= 68.9% | Valid: loss=2.736, acc= 57.5% |\n",
      "| Epoch  58, time= 36.9ms/ 11.7ms | Train: loss=2.327, acc= 68.9% | Valid: loss=2.735, acc= 57.7% |\n",
      "| Epoch  59, time= 36.1ms/ 11.7ms | Train: loss=2.328, acc= 68.7% | Valid: loss=2.751, acc= 56.7% | lr=2.1e-04\n",
      "| Epoch  60, time= 36.1ms/ 11.8ms | Train: loss=2.315, acc= 69.1% | Valid: loss=2.729, acc= 58.0% |\n",
      "tensor(1.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "| Epoch  61, time= 36.7ms/ 11.7ms | Train: loss=2.315, acc= 69.4% | Valid: loss=2.733, acc= 57.4% |\n",
      "| Epoch  62, time= 36.7ms/ 11.8ms | Train: loss=2.314, acc= 69.3% | Valid: loss=2.734, acc= 57.5% |\n",
      "| Epoch  63, time= 36.6ms/ 11.8ms | Train: loss=2.319, acc= 69.1% | Valid: loss=2.742, acc= 57.3% |\n",
      "| Epoch  64, time= 36.7ms/ 11.7ms | Train: loss=2.315, acc= 69.2% | Valid: loss=2.738, acc= 57.7% | lr=6.9e-05\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> Test on task  0 - cifar10-2      : loss=0.939, acc= 87.4% <<<\n",
      ">>> Test on task  1 - cifar100-3     : loss=25.180, acc= 59.3% <<<\n",
      ">>> Test on task  2 - cifar10-4      : loss=24.209, acc= 89.0% <<<\n",
      ">>> Test on task  3 - cifar100-4     : loss=25.167, acc= 59.7% <<<\n",
      ">>> Test on task  4 - cifar10-1      : loss=24.302, acc= 80.9% <<<\n",
      ">>> Test on task  5 - cifar100-1     : loss=25.366, acc= 59.6% <<<\n",
      ">>> Test on task  6 - cifar100-2     : loss=25.189, acc= 59.1% <<<\n",
      ">>> Test on task  7 - cifar10-3      : loss=24.055, acc= 93.3% <<<\n",
      ">>> Test on task  8 - cifar10-0      : loss=24.206, acc= 88.2% <<<\n",
      ">>> Test on task  9 - cifar100-0     : loss=25.196, acc= 58.1% <<<\n",
      "Save at res/alexnet_cifar_si_xda_0.txt\n",
      "****************************************************************************************************\n",
      "Accuracies =\n",
      "\t 90.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
      "\t 89.1%  60.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
      "\t 88.5%  58.0%  90.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
      "\t 89.0%  59.9%  87.8%  60.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
      "\t 89.0%  57.5%  90.2%  58.8%  82.8%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
      "\t 88.7%  60.0%  87.8%  60.3%  81.2%  61.6%   0.0%   0.0%   0.0%   0.0% \n",
      "\t 87.7%  59.2%  89.7%  58.0%  81.4%  60.7%  59.1%   0.0%   0.0%   0.0% \n",
      "\t 87.3%  57.8%  88.2%  54.3%  79.4%  59.5%  58.3%  95.1%   0.0%   0.0% \n",
      "\t 86.5%  58.9%  88.2%  57.8%  79.9%  61.5%  57.1%  92.3%  92.8%   0.0% \n",
      "\t 87.3%  59.3%  89.1%  59.6%  80.9%  59.6%  59.1%  93.3%  88.2%  58.1% \n",
      "****************************************************************************************************\n",
      "Done!\n",
      "[Elapsed time = 1.4 h]\n"
     ]
    }
   ],
   "source": [
    "net = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"models/\" + args.approach + \".model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task order = [2, 8, 4, 9, 1, 6, 7, 3, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "data_raw, taskcla, inputsize = dataloader.get(seed=args.seed)\n",
    "data_train = data_raw[t]['train']['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.2)\n",
       "  (drop2): Dropout(p=0.5)\n",
       "  (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (last): ModuleList(\n",
       "    (0): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (5): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (6): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (7): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (8): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (9): Linear(in_features=2048, out_features=20, bias=True)\n",
       "  )\n",
       "  (c1_xda): XdA(\n",
       "    (norm): LayerNorm(torch.Size([64, 29, 29]), eps=1e-05, elementwise_affine=False)\n",
       "    (phi): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (4): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (5): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (6): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (7): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (8): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "        (9): Parameter containing: [torch.FloatTensor of size 64x29x29]\n",
       "    )\n",
       "  )\n",
       "  (c2_xda): XdA(\n",
       "    (norm): LayerNorm(torch.Size([128, 12, 12]), eps=1e-05, elementwise_affine=False)\n",
       "    (phi): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (4): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (5): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (6): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (7): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (8): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "        (9): Parameter containing: [torch.FloatTensor of size 128x12x12]\n",
       "    )\n",
       "  )\n",
       "  (c3_xda): XdA(\n",
       "    (norm): LayerNorm(torch.Size([256, 5, 5]), eps=1e-05, elementwise_affine=False)\n",
       "    (phi): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (4): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (5): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (6): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (7): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (8): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "        (9): Parameter containing: [torch.FloatTensor of size 256x5x5]\n",
       "    )\n",
       "  )\n",
       "  (fc1_xda): XdA(\n",
       "    (norm): LayerNorm(torch.Size([2048]), eps=1e-05, elementwise_affine=False)\n",
       "    (phi): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (4): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (5): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (6): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (7): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (8): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (9): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "    )\n",
       "  )\n",
       "  (fc2_xda): XdA(\n",
       "    (norm): LayerNorm(torch.Size([2048]), eps=1e-05, elementwise_affine=False)\n",
       "    (phi): ParameterList(\n",
       "        (0): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (1): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (2): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (3): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (4): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (5): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (6): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (7): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (8): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "        (9): Parameter containing: [torch.FloatTensor of size 2048]\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.approach = 'si_xda'\n",
    "args.network = 'alexnet_' + args.approach\n",
    "load_network_and_approach(args)\n",
    "net = network.Net(inputsize, taskcla)\n",
    "net.load_state_dict(torch.load(\"models/si_xda.model\"))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (drop1): Dropout(p=0.2)\n",
       "  (drop2): Dropout(p=0.5)\n",
       "  (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (last): ModuleList(\n",
       "    (0): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (5): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (6): Linear(in_features=2048, out_features=20, bias=True)\n",
       "    (7): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (8): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (9): Linear(in_features=2048, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.approach = 'sgd'\n",
    "args.network = 'alexnet_' + args.approach\n",
    "load_network_and_approach(args)\n",
    "sgd_net = network.Net(inputsize, taskcla)\n",
    "sgd_net.load_state_dict(torch.load(\"models/sgd.model\"))\n",
    "sgd_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.from_numpy(np.array([125.3, 123.0, 113.9], dtype=np.float32))\n",
    "std = torch.from_numpy(np.array([63.0, 62.1, 66.7], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_img = data_train.transpose(1, 3)\n",
    "data_train_img = data_train_img.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9000, 32, 32, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_img_norm = (data_train_img[:,:,:,:]*std + mean)/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Image and Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no = 77\n",
    "neuron_no = 30\n",
    "cmap = \"PRGn\"\n",
    "x = data_train[sample_no].view(1, 3, 32, 32).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XdA Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_act = net.conv1(x.cpu())\n",
    "c1_gated_act = net.c1_xda(c1_act, t)\n",
    "c1_act_np = c1_act[0][neuron_no].data.cpu().numpy()\n",
    "c1_gated_act_np = c1_gated_act[0][neuron_no].data.cpu().numpy()\n",
    "\n",
    "\n",
    "h = net.drop1(c1_gated_act)\n",
    "h = net.maxpool(h)\n",
    "c2_act = net.conv2(h)\n",
    "c2_gated_act = net.c2_xda(c2_act, t)\n",
    "c2_act_np = c2_act[0][neuron_no].data.cpu().numpy()\n",
    "c2_gated_act_np = c2_gated_act[0][neuron_no].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_act = sgd_net.conv1(x.cpu())\n",
    "c1_gated_act = sgd_net.relu(c1_act)\n",
    "c1_act_np = c1_act[0][neuron_no].data.cpu().numpy()\n",
    "c1_gated_act_np = c1_gated_act[0][neuron_no].data.cpu().numpy()\n",
    "\n",
    "\n",
    "h = sgd_net.drop1(c1_gated_act)\n",
    "h = sgd_net.maxpool(h)\n",
    "c2_act = sgd_net.conv2(h)\n",
    "c2_gated_act = sgd_net.relu(c2_act)\n",
    "c2_act_np = c2_act[0][neuron_no].data.cpu().numpy()\n",
    "c2_gated_act_np = c2_gated_act[0][neuron_no].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fce84feb4e0>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEJny/wAnbvOnLfHcowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_train_img_norm[sample_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fce84f74438>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAD8CAYAAADqmhgGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(c1_act_np, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fce84e8ee10>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(c1_gated_act_np, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fce84e2f470>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAAD8CAYAAAD9uIjPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSseFzcxKx4XNzErHhc3MSuf/Ayq7oRdTTVoPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(c2_act_np, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fce84d4ac88>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAD8CAYAAADnhGhBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(c2_gated_act_np, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_weights_img = net.conv1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_weights_img_np = c1_weights_img.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_weights_img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c1_weights_img_np[20][0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
